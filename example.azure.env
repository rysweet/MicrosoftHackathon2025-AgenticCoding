# Azure OpenAI Configuration for amplihack launch --with-proxy-config
# Copy this file and replace with your actual Azure OpenAI credentials

# Required: Your Azure OpenAI API key
OPENAI_API_KEY="your-azure-openai-api-key-here"  # pragma: allowlist secret

# Required: Azure OpenAI endpoint URL
# Format: https://<resource-name>.openai.azure.com/openai/deployments/<deployment-name>/chat/completions?api-version=<version>
OPENAI_BASE_URL="https://your-resource.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2025-01-01-preview"

# Required: Azure-specific settings
AZURE_OPENAI_KEY="your-azure-openai-api-key-here"  # pragma: allowlist secret
AZURE_API_VERSION="2025-01-01-preview"

# Model mappings - adjust to your Azure deployment names
BIG_MODEL="gpt-4"           # Maps to Claude's largest model
MIDDLE_MODEL="gpt-4"        # Maps to Claude's mid-tier model
SMALL_MODEL="gpt-4-turbo"   # Maps to Claude's smallest/fastest model

# Optional: Expected Anthropic API key for client validation
# Uncomment and set if you want to require a specific key from Claude Code
# ANTHROPIC_API_KEY="expected-key-from-claude"  # pragma: allowlist secret

# Server settings
HOST="127.0.0.1"  # Use localhost for security
PORT="8082"
LOG_LEVEL="INFO"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL

# Performance settings - optimized for large context
MAX_TOKENS_LIMIT="512000"  # 512k tokens - maximum context size
MIN_TOKENS_LIMIT="4096"    # Minimum tokens (to avoid errors with thinking model)
REQUEST_TIMEOUT="300"      # 5 minutes for large requests
MAX_RETRIES="2"            # Retry on transient failures

# Alternative Azure configurations (commented examples):

# Example 1: Azure OpenAI in East US 2
# OPENAI_BASE_URL="https://my-oai-eastus2.openai.azure.com/openai/deployments/gpt-4-turbo/chat/completions?api-version=2025-01-01-preview"
# BIG_MODEL="gpt-4-turbo"
# MIDDLE_MODEL="gpt-4-turbo"
# SMALL_MODEL="gpt-4-turbo"

# Example 2: Azure OpenAI with GPT-4o
# OPENAI_BASE_URL="https://my-resource.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview"
# BIG_MODEL="gpt-4o"
# MIDDLE_MODEL="gpt-4o"
# SMALL_MODEL="gpt-4o-mini"

# Notes:
# 1. Replace all placeholder values with your actual Azure credentials
# 2. The deployment name in OPENAI_BASE_URL must match your Azure deployment
# 3. MAX_TOKENS_LIMIT is set to 512k for maximum context window
# 4. When using with amplihack, the Azure persistence prompt is automatically included
# 5. For troubleshooting, set LOG_LEVEL="DEBUG"
