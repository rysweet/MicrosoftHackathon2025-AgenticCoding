# Chat API Proxy Configuration - Routes gpt-5 to Chat endpoint
# For testing: uvx amplihack launch --with-proxy-config proxy_config_chat_api.env

OPENAI_API_KEY=proxy-key  # pragma: allowlist secret
OPENAI_BASE_URL="https://your-resource.cognitiveservices.azure.com"

# Enable LiteLLM routing
AMPLIHACK_USE_LITELLM=true
USE_LITELLM_ROUTER=true

# Proxy settings
PROXY_TYPE=integrated
PROXY_MODE=internal
HOST=127.0.0.1
PORT=8000

# Azure Chat API settings - REPLACE WITH YOUR VALUES
AZURE_OPENAI_KEY=YOUR_API_KEY_HERE  # pragma: allowlist secret
AZURE_OPENAI_API_KEY=YOUR_API_KEY_HERE  # pragma: allowlist secret
AZURE_OPENAI_API_VERSION=2025-01-01-preview
AZURE_OPENAI_ENDPOINT=https://your-resource.cognitiveservices.azure.com

# Model configuration - Chat API uses gpt-5
BIG_MODEL=gpt-5
MIDDLE_MODEL=gpt-5
SMALL_MODEL=gpt-5

# Performance settings
MAX_TOKENS_LIMIT=512000
REQUEST_TIMEOUT=300
