"""
Agent content generator for Agent Bundle Generator.

Generates actual agent content, tests, and documentation from requirements.
"""

import logging
import time
import uuid
from typing import Any, Dict, List, Optional

from .exceptions import GenerationError
from .models import AgentRequirement, ExtractedIntent, GeneratedAgent

logger = logging.getLogger(__name__)


class AgentGenerator:
    """
    Generate agent content from extracted requirements.

    Creates complete agent markdown files with proper structure and documentation.
    """

    # Agent template structure
    AGENT_TEMPLATE = """# {name}

{description}

## Role

{role}

## Model Configuration

Model: {model}

## Capabilities

{capabilities}

## Core Responsibilities

{responsibilities}

## Implementation

{implementation}

## Context and Philosophy

{philosophy}

## Error Handling

{error_handling}

## Performance Considerations

{performance}

## Dependencies

{dependencies}

## Example Usage

{examples}

## Testing

{testing}

---
Generated by Agent Bundle Generator v1.0.0
"""

    def __init__(self, template_path: Optional[str] = None):
        """
        Initialize the agent generator.

        Args:
            template_path: Optional path to custom templates (unused currently)
        """
        self.template_path = template_path

    def generate(
        self, intent: ExtractedIntent, options: Optional[Dict[str, Any]] = None
    ) -> List[GeneratedAgent]:
        """
        Generate agents from extracted intent.

        Args:
            intent: ExtractedIntent with requirements
            options: Optional generation options

        Returns:
            List of GeneratedAgent objects

        Raises:
            GenerationError: If generation fails
        """
        options = options or {}
        generated_agents = []

        for requirement in intent.agent_requirements:
            try:
                agent = self._generate_single_agent(requirement, intent, options)
                generated_agents.append(agent)
            except Exception as e:
                raise GenerationError(
                    f"Failed to generate agent {requirement.name}: {e!s}",
                    agent_name=requirement.name,
                    generation_stage="agent_generation",
                )

        return generated_agents

    def _generate_single_agent(
        self, requirement: AgentRequirement, intent: ExtractedIntent, options: Dict[str, Any]
    ) -> GeneratedAgent:
        """Generate a single agent from requirement."""
        start_time = time.time()

        # Generate agent content sections
        description = self._generate_description(requirement, intent)
        capabilities_text = self._generate_capabilities(requirement.capabilities)
        responsibilities = self._generate_responsibilities(requirement, intent)
        implementation = self._generate_implementation(requirement, intent)
        philosophy = self._generate_philosophy(requirement)
        error_handling = self._generate_error_handling(requirement)
        performance = self._generate_performance(requirement, intent.complexity)
        dependencies_text = self._generate_dependencies(requirement.dependencies)
        examples = self._generate_examples(requirement)
        testing = self._generate_testing(requirement)

        # Format the complete agent content
        content = self.AGENT_TEMPLATE.format(
            name=requirement.name.title().replace("_", " "),
            description=description,
            role=requirement.role,
            model="inherit",
            capabilities=capabilities_text,
            responsibilities=responsibilities,
            implementation=implementation,
            philosophy=philosophy,
            error_handling=error_handling,
            performance=performance,
            dependencies=dependencies_text,
            examples=examples,
            testing=testing,
        )

        # Generate test files if requested
        tests = []
        if options.get("include_tests", True):
            tests = self._generate_test_files(requirement)

        # Generate documentation if requested
        documentation = ""
        if options.get("include_docs", True):
            documentation = self._generate_documentation(requirement)

        generation_time = time.time() - start_time

        return GeneratedAgent(
            id=uuid.uuid4(),
            name=requirement.name,
            type=requirement.suggested_type,
            role=requirement.role,
            description=description,
            content=content,
            model="inherit",
            capabilities=requirement.capabilities,
            dependencies=requirement.dependencies,
            tests=tests,
            documentation=documentation,
            generation_time_seconds=generation_time,
        )

    def _generate_description(self, req: AgentRequirement, intent: ExtractedIntent) -> str:
        """Generate agent description."""
        return f"""
{req.purpose}

This {req.suggested_type} agent operates within the {intent.domain} domain
to provide specialized functionality for {intent.action} operations.
        """.strip()

    def _generate_capabilities(self, capabilities: List[str]) -> str:
        """Generate capabilities section."""
        if not capabilities:
            return "- General processing and analysis"

        lines = []
        for capability in capabilities:
            lines.append(
                f"- **{capability.title()}**: Perform {capability} operations on input data"
            )

        return "\n".join(lines)

    def _generate_responsibilities(self, req: AgentRequirement, intent: ExtractedIntent) -> str:
        """Generate responsibilities section."""
        responsibilities = [
            f"1. **Primary**: {req.purpose}",
            "2. **Validation**: Ensure input data meets requirements",
            f"3. **Processing**: Execute {', '.join(req.capabilities[:3]) if req.capabilities else 'core'} operations",
            "4. **Error Handling**: Gracefully handle failures and edge cases",
            "5. **Reporting**: Provide clear feedback and results",
        ]

        if intent.complexity == "advanced":
            responsibilities.extend(
                [
                    "6. **Optimization**: Maximize performance and efficiency",
                    "7. **Monitoring**: Track operational metrics",
                    "8. **Integration**: Coordinate with other system components",
                ]
            )

        return "\n".join(responsibilities)

    def _generate_implementation(self, req: AgentRequirement, intent: ExtractedIntent) -> str:
        """Generate implementation details."""
        implementation = f"""
### Input Processing

The agent accepts input in the following formats:
- Structured data (JSON, YAML)
- Text-based commands
- File paths for batch processing

### Core Algorithm

```python
def process(input_data):
    # Validate input
    validated = validate_input(input_data)

    # Apply transformations
    processed = apply_{req.capabilities[0] if req.capabilities else "default"}(validated)

    # Generate output
    return format_output(processed)
```

### Output Format

Results are returned in a structured format with:
- Status indicator
- Processed data
- Metadata (processing time, warnings, etc.)
- Error information (if applicable)
        """

        if intent.complexity in ["standard", "advanced"]:
            implementation += """

### Advanced Features

- Parallel processing for large datasets
- Caching for frequently accessed data
- Incremental processing capabilities
- Real-time streaming support
"""

        return implementation.strip()

    def _generate_philosophy(self, req: AgentRequirement) -> str:
        """Generate philosophy section."""
        return """
This agent follows the amplihack philosophy of:  # noqa

- **Ruthless Simplicity**: Start simple, add complexity only when justified
- **Modular Design**: Self-contained with clear interfaces
- **Zero-BS Implementation**: No stubs or placeholders, only working code
- **Regeneratable**: Can be rebuilt from specification
- **Trust Through Transparency**: Clear documentation and error messages

The agent prioritizes clarity and maintainability over premature optimization.
        """.strip()

    def _generate_error_handling(self, req: AgentRequirement) -> str:
        """Generate error handling section."""
        return """
The agent implements comprehensive error handling:

1. **Input Validation Errors**
   - Clear messages about what's wrong
   - Suggestions for correction
   - Examples of valid input

2. **Processing Errors**
   - Graceful degradation when possible
   - Partial results with warnings
   - Detailed error context for debugging

3. **Resource Errors**
   - Timeout handling with configurable limits
   - Memory management and cleanup
   - Retry logic with exponential backoff

4. **Recovery Strategies**
   - Automatic retry for transient failures
   - Fallback to simpler processing modes
   - State preservation for resumption
        """.strip()

    def _generate_performance(self, req: AgentRequirement, complexity: str) -> str:
        """Generate performance considerations."""
        base_performance = """
- **Latency**: Optimized for sub-second response times
- **Throughput**: Handles standard workloads efficiently
- **Memory**: Minimal memory footprint
        """

        if complexity == "simple":
            return base_performance + "\n- **Scalability**: Suitable for small to medium datasets"

        if complexity == "standard":
            return (
                base_performance
                + """
- **Scalability**: Handles medium to large datasets
- **Caching**: Smart caching for repeated operations
- **Batching**: Efficient batch processing support
            """
            )

        # advanced
        return (
            base_performance
            + """
- **Scalability**: Enterprise-scale data processing
- **Caching**: Multi-level caching with TTL
- **Batching**: Advanced batch processing with parallelization
- **Streaming**: Real-time stream processing capabilities
- **Resource Management**: Dynamic resource allocation
- **Monitoring**: Built-in performance metrics
            """
        )

    def _generate_dependencies(self, dependencies: List[str]) -> str:
        """Generate dependencies section."""
        if not dependencies:
            return "No external dependencies required."

        lines = ["This agent depends on:"]
        for dep in dependencies:
            lines.append(f"- {dep}")

        return "\n".join(lines)

    def _generate_examples(self, req: AgentRequirement) -> str:
        """Generate usage examples."""
        return f"""
```python
# Example 1: Basic usage
result = {req.name}.process("input data")
print(result.status)  # "success"  # noqa: T201 (print) (print)

# Example 2: With options
options = {{
    "validate": True,
    "format": "json",
    "verbose": False
}}
result = {req.name}.process("input data", options)

# Example 3: Batch processing
inputs = ["data1", "data2", "data3"]
results = {req.name}.process_batch(inputs)
for result in results:
    if result.success:
        print(f"Processed: {{result.data}}")  # noqa: T201 (print)
```
        """.strip()

    def _generate_testing(self, req: AgentRequirement) -> str:
        """Generate testing section."""
        return f"""
### Test Coverage

- Unit tests for all {len(req.capabilities)} capabilities
- Integration tests with common workflows
- Edge case handling tests
- Performance benchmarks
- Security validation tests

### Running Tests

```bash
# Run all tests
pytest tests/test_{req.name}.py

# Run specific test category
pytest tests/test_{req.name}.py::TestValidation

# Run with coverage
pytest --cov={req.name} tests/
```

### Test Data

Test fixtures are provided in `tests/fixtures/{req.name}/`
        """.strip()

    def _generate_test_files(self, req: AgentRequirement) -> List[str]:
        """Generate test file contents."""
        test_content = f'''"""
Tests for {req.name.title().replace("_", " ")}

These are functional tests that verify the agent markdown file structure
and content without importing it as a Python module. Generated agent bundles
are standalone packages, not submodules of amplihack.  # noqa
"""

import pytest
from pathlib import Path


class Test{req.name.title().replace("_", "")}:
    """Test suite for {req.name} agent bundle."""

    def test_agent_file_exists(self):
        """Test that agent markdown file exists."""
        agents_dir = Path(__file__).parent.parent / "agents"
        agent_file = agents_dir / "{req.name}.md"
        assert agent_file.exists(), f"Agent file should exist at {{agent_file}}"

    def test_agent_content_structure(self):
        """Test agent file has required sections."""
        agents_dir = Path(__file__).parent.parent / "agents"
        agent_file = agents_dir / "{req.name}.md"
        content = agent_file.read_text()

        # Check required sections exist
        assert "## Role" in content, "Should have Role section"
        assert "## Capabilities" in content, "Should have Capabilities section"
        assert "## Implementation" in content, "Should have Implementation section"
        assert "## Testing" in content, "Should have Testing section"

    def test_agent_content_not_empty(self):
        """Test agent file has substantial content."""
        agents_dir = Path(__file__).parent.parent / "agents"
        agent_file = agents_dir / "{req.name}.md"
        content = agent_file.read_text()

        assert len(content) > 500, "Agent file should have substantial content"
        assert "TODO" not in content, "Agent should not contain TODO placeholders"  # noqa
        assert "PLACEHOLDER" not in content, "Agent should not contain PLACEHOLDER text"

    def test_manifest_includes_agent(self):
        """Test that manifest.json includes this agent."""
        manifest_file = Path(__file__).parent.parent / "manifest.json"
        if manifest_file.exists():
            import json
            manifest = json.loads(manifest_file.read_text())
            agent_names = [a.get("name") for a in manifest.get("agents", [])]
            assert "{req.name}" in agent_names, "Agent should be listed in manifest"
'''

        return [test_content]

    def _generate_documentation(self, req: AgentRequirement) -> str:
        """Generate additional documentation."""
        return f"""
# {req.name.title().replace("_", " ")} - Extended Documentation

## Overview

{req.purpose}

## Architecture

The agent follows a pipeline architecture:

1. **Input Stage**: Receives and validates input
2. **Processing Stage**: Applies core logic
3. **Output Stage**: Formats and returns results

## Configuration

Configuration options can be provided via:
- Environment variables
- Configuration files (JSON/YAML)
- Runtime parameters

## Integration Guide

### Using the Agent with Claude Code

This agent bundle is designed to be used with Claude Code. The agent markdown file
can be referenced in your Claude Code configuration or imported as a custom agent.

**Add to your .claude/agents directory:**

```bash
# Copy agent to your project's Claude configuration
cp agents/{req.name}.md /path/to/your/project/.claude/agents/
```

**Reference in Claude Code:**

```markdown
@.claude/agents/{req.name}.md
```

### Standalone Usage

The agent markdown file contains the complete specification and can be used
as documentation or imported into other AI systems that support markdown-based
agent definitions.

## Troubleshooting

Common issues and solutions:

1. **File Not Found**: Ensure the agent file is in the agents/ directory
2. **Validation Error**: Check that the agent markdown has required sections
3. **Integration Issues**: Verify Claude Code can access the .claude/agents directory
4. **Format Issues**: Ensure the agent markdown follows the expected structure

## Version History

- v1.0.0: Initial release
        """.strip()

    def validate_agent(self, agent: GeneratedAgent) -> List[str]:
        """
        Validate generated agent content.

        Args:
            agent: GeneratedAgent to validate

        Returns:
            List of validation issues (empty if valid)
        """
        issues = []

        # Check content length
        if len(agent.content) < 100:
            issues.append(f"Agent {agent.name} content too short")

        # Check required sections
        required_sections = ["Role", "Capabilities", "Implementation"]
        for section in required_sections:
            if f"## {section}" not in agent.content:
                issues.append(f"Missing required section: {section}")

        # Check for placeholders
        if "TODO" in agent.content or "PLACEHOLDER" in agent.content:
            issues.append("Content contains placeholders")

        return issues
