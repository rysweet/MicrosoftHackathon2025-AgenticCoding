# Example proxy configuration for Azure OpenAI integration
# Copy this file and rename to .env, then fill in your values

# Required for proxy operation: OpenAI API key (can be your Azure key)
OPENAI_API_KEY=your-azure-api-key-here

# Required for Azure: Azure OpenAI configuration
# Note: AZURE_OPENAI_API_KEY is required (not AZURE_OPENAI_KEY)
AZURE_OPENAI_API_KEY=your-azure-api-key-here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_BASE_URL=https://your-resource.openai.azure.com/openai/responses
AZURE_OPENAI_API_VERSION=2025-04-01-preview

# Optional: Model deployment mappings
BIG_MODEL=gpt-5-codex
MIDDLE_MODEL=gpt-5-codex
SMALL_MODEL=gpt-5-codex

# Optional: Proxy server configuration
HOST=127.0.0.1
PORT=9001
LOG_LEVEL=INFO

# Optional: Performance settings
MAX_TOKENS_LIMIT=512000
MIN_TOKENS_LIMIT=4096
REQUEST_TIMEOUT=300
MAX_RETRIES=10

# Optional: Enable LiteLLM for Azure routing
AMPLIHACK_USE_LITELLM=true
