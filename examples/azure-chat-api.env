# Example Configuration: Azure Chat API Endpoint
# This configuration uses the Azure Chat Completions API (/chat/completions)
# Detection: URL contains "/chat" → Routes through LiteLLM → Azure Chat API

# Required: Your Azure OpenAI API key
OPENAI_API_KEY="your-azure-api-key-here"  # pragma: allowlist secret

# Required: Azure Chat API endpoint URL - the proxy detects "/chat" in the URL
OPENAI_BASE_URL="https://your-resource.cognitiveservices.azure.com/openai/deployments/gpt-5/chat/completions?api-version=2025-01-01-preview"

# Required: Azure-specific settings
AZURE_OPENAI_KEY="your-azure-api-key-here"  # pragma: allowlist secret
AZURE_API_VERSION="2025-01-01-preview"

# Model mappings - use gpt-5 for Chat API
BIG_MODEL="gpt-5"
MIDDLE_MODEL="gpt-5"
SMALL_MODEL="gpt-5"

# Proxy settings
AMPLIHACK_USE_LITELLM=false  # Use integrated proxy routing
PROXY_TYPE=integrated_azure_chat
HOST=127.0.0.1
PORT=8000

# Performance settings
MAX_TOKENS_LIMIT=512000
REQUEST_TIMEOUT=300
MAX_RETRIES=2
LOG_LEVEL=INFO

# Example endpoints (replace with your actual Azure resource):
# https://ai-adapt-oai-eastus2.cognitiveservices.azure.com/openai/deployments/gpt-5/chat/completions?api-version=2025-01-01-preview