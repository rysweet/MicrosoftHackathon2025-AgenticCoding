# Example .env configuration for Passthrough Mode
# This mode tries Anthropic API first, then falls back to Azure OpenAI on 429 errors

# =============================================================================
# PASSTHROUGH MODE CONFIGURATION
# =============================================================================

# Enable passthrough mode (default: false)
PASSTHROUGH_MODE=true

# Enable fallback to Azure OpenAI when Anthropic returns 429 errors (default: true)
PASSTHROUGH_FALLBACK_ENABLED=true

# Maximum retries before giving up (default: 3)
PASSTHROUGH_MAX_RETRIES=3

# Delay between retries in seconds (default: 1.0)
PASSTHROUGH_RETRY_DELAY=1.0

# Number of 429 failures before switching to Azure fallback (default: 2)
PASSTHROUGH_FALLBACK_AFTER_FAILURES=2

# =============================================================================
# ANTHROPIC API CONFIGURATION (PRIMARY)
# =============================================================================

# Required: Your Anthropic API key
ANTHROPIC_API_KEY=sk-ant-api03-your-anthropic-key-here

# =============================================================================
# AZURE OPENAI CONFIGURATION (FALLBACK)
# =============================================================================

# Required for fallback: Your Azure OpenAI endpoint
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com

# Required for fallback: Your Azure OpenAI API key
AZURE_OPENAI_API_KEY=your-azure-api-key-here

# Optional: API version (default: 2024-02-01)
AZURE_OPENAI_API_VERSION=2024-02-01

# =============================================================================
# CLAUDE MODEL TO AZURE DEPLOYMENT MAPPINGS
# =============================================================================

# Map Claude models to your Azure deployments
# These are used when falling back to Azure OpenAI

# Claude 3.5 Sonnet -> Your GPT-4 deployment
AZURE_CLAUDE_SONNET_DEPLOYMENT=gpt-4

# Claude 3.5 Haiku -> Your GPT-4o-mini deployment
AZURE_CLAUDE_HAIKU_DEPLOYMENT=gpt-4o-mini

# Claude 3 Opus -> Your GPT-4 deployment
AZURE_CLAUDE_OPUS_DEPLOYMENT=gpt-4

# =============================================================================
# PROXY SERVER CONFIGURATION
# =============================================================================

# Port for the proxy server (default: 8080)
PORT=8080

# Host for the proxy server (default: 127.0.0.1)
HOST=127.0.0.1

# Request timeout in seconds (default: 60)
REQUEST_TIMEOUT=60

# Log level (default: INFO)
LOG_LEVEL=INFO

# =============================================================================
# USAGE INSTRUCTIONS
# =============================================================================

# 1. Copy this file to .env in your project directory
# 2. Fill in your actual API keys and endpoints
# 3. Adjust the deployment mappings to match your Azure OpenAI deployments
# 4. Start the proxy: python -m amplihack.proxy.server
# 5. Send requests to http://localhost:8080/v1/messages

# The proxy will:
# - First try to send Claude model requests to Anthropic API
# - If it gets a 429 rate limit error, switch to Azure OpenAI fallback
# - After 2 failures (configurable), automatically use Azure for subsequent requests
# - Reset back to Anthropic after 5 minutes without failures

# Example request:
# curl -X POST http://localhost:8080/v1/messages \
#   -H "Content-Type: application/json" \
#   -H "x-api-key: your-anthropic-key" \
#   -d '{
#     "model": "claude-3-5-sonnet-20241022",
#     "max_tokens": 1000,
#     "messages": [{"role": "user", "content": "Hello!"}]
#   }'
