# Optimized LiteLLM Configuration for Performance
# Maintains all user requirements while improving performance

model_list:
  # Claude Code model mappings - these match what Claude Code sends
  - model_name: claude-3-5-sonnet-20241022
    litellm_params:
      model: azure/gpt-5
      api_base: https://ai-adapt-oai-eastus2.openai.azure.com
      api_key: ${AZURE_OPENAI_KEY}
      api_version: preview
      max_tokens: 512000 # Full token limit for Claude Code compatibility
      timeout: 60
      max_retries: 2
      retry_delay: 1.0
      stream_timeout: 30
      connect_timeout: 10
      temperature: 1.0 # Required for Azure Responses API
  - model_name: claude-3-5-haiku-20241022
    litellm_params:
      model: azure/gpt-5 # Map to same Azure model for now
      api_base: https://ai-adapt-oai-eastus2.openai.azure.com
      api_key: ${AZURE_OPENAI_KEY}
      api_version: preview
      max_tokens: 512000
      timeout: 60
      max_retries: 2
      retry_delay: 1.0
      stream_timeout: 30
      connect_timeout: 10
      temperature: 1.0
  # Legacy mappings for backward compatibility
  - model_name: gpt-5
    litellm_params:
      model: azure/gpt-5
      api_base: https://ai-adapt-oai-eastus2.openai.azure.com
      api_key: ${AZURE_OPENAI_KEY}
      api_version: preview
      max_tokens: 4096
      timeout: 60
      max_retries: 2
      retry_delay: 1.0
      stream_timeout: 30
      connect_timeout: 10
  - model_name: gpt-4
    litellm_params:
      model: azure/gpt-5
      api_base: https://ai-adapt-oai-eastus2.openai.azure.com
      api_key: ${AZURE_OPENAI_KEY}
      api_version: preview
      max_tokens: 4096
      timeout: 60
      max_retries: 2
      retry_delay: 1.0
      stream_timeout: 30
      connect_timeout: 10

general_settings:
  master_key: ${LITELLM_MASTER_KEY}
  # Performance optimizations
  port: 9001
  host: 127.0.0.1
  # Connection pooling optimization
  max_budget: 100.0
  budget_duration: "1d"
  # Concurrent request handling
  max_parallel_requests: 50
  # Health check optimization
  health_check_interval: 30
  # Memory optimization
  enable_pre_call_checks: false # Disable expensive pre-flight checks
  # Startup optimization
  disable_spend_logs: true # Reduce I/O overhead

litellm_settings:
  # Core settings preserved for functionality
  telemetry: false
  set_verbose: false
  drop_params: true
  # Performance optimizations
  cache: true # Enable response caching
  cache_type: "redis" # Use Redis for better performance (fallback to memory)
  cache_params:
    redis_host: "localhost"
    redis_port: 6379
    default_ttl: 300 # 5 minute cache TTL
  # Connection optimization
  num_retries: 2 # Global retry setting
  request_timeout: 60 # Global timeout optimization
  # Async optimization
  async_fallbacks: true
  # Memory optimization
  max_tokens_limit: 128000 # Global limit to prevent memory issues
  # Startup optimization
  disable_streaming_logging: true
  disable_guardrails: true # Remove unnecessary overhead

# Router optimization for load balancing
router_settings:
  routing_strategy: "round-robin"
  fallbacks:
    - model: "azure/gpt-4" # Fallback model for reliability
  retry_policy:
    max_retries: 3
    base_delay: 1.0
    max_delay: 8.0
    exponential_base: 2.0
  # Health monitoring
  health_check_interval: 30
  unhealthy_threshold: 3
  healthy_threshold: 2
