# Manual Documentation Testing Plan

This document provides human verification tests that complement automated testing.
Perform these tests BEFORE and AFTER the documentation reorganization.

## Test Status Legend

- â¬œ Not started
- ğŸŸ¨ In progress
- âœ… Passed
- âŒ Failed

---

## Pre-Reorganization Baseline (Expected: Many Failures)

Run these tests to establish baseline. **These SHOULD fail** - that's why we're reorganizing!

### Test 1: New User Experience â¬œ

**Objective**: Verify a new user can get started quickly.

**Steps**:

1. Open `docs/index.md` in browser
2. Can you find "Get Started" section within 5 seconds? â¬œ
3. Can you find "Prerequisites" link? â¬œ
4. Can you find "Installation" guide? â¬œ
5. Can you find "Quick Start" tutorial? â¬œ

**Expected Pre-Reorg**: ğŸŸ¨ Some links may be broken or hard to find
**Expected Post-Reorg**: âœ… All links clear and functional

**Actual Result (Pre)**:
```
[Record observations here]
```

**Actual Result (Post)**:
```
[Record observations here]
```

---

### Test 2: Goal-Seeking Agent Discoverability â¬œ

**Objective**: Verify goal-seeking agents are prominently linked (user requirement).

**Steps**:

1. Open `docs/index.md`
2. Search for "goal" or "autonomous agents" â¬œ
3. Is there a clear section dedicated to goal-seeking agents? â¬œ
4. Are there multiple links to goal-seeking agent docs? â¬œ
5. Click first goal-seeking link - does it work? â¬œ

**Expected Pre-Reorg**: âŒ May be buried or missing
**Expected Post-Reorg**: âœ… Prominently featured with working links

**Actual Result (Pre)**:
```
[Record observations here]
```

**Actual Result (Post)**:
```
[Record observations here]
```

---

### Test 3: Navigation Efficiency â¬œ

**Objective**: Verify docs are accessible within 3 clicks.

**Steps**:

1. Start at `docs/index.md`
2. Find documentation for: `/ultrathink` command
   - Clicks required: ___ â¬œ
3. Find documentation for: DDD workflow
   - Clicks required: ___ â¬œ
4. Find documentation for: Neo4j memory system
   - Clicks required: ___ â¬œ
5. Find documentation for: Creating custom agents
   - Clicks required: ___ â¬œ

**Expected Pre-Reorg**: ğŸŸ¨ 4-5 clicks for some topics
**Expected Post-Reorg**: âœ… â‰¤3 clicks for all topics

**Actual Result (Pre)**:
```
/ultrathink: ___ clicks
DDD workflow: ___ clicks
Neo4j memory: ___ clicks
Custom agents: ___ clicks
```

**Actual Result (Post)**:
```
/ultrathink: ___ clicks
DDD workflow: ___ clicks
Neo4j memory: ___ clicks
Custom agents: ___ clicks
```

---

### Test 4: Link Integrity â¬œ

**Objective**: Verify no broken links in common user paths.

**Steps**:

1. Open `docs/index.md`
2. Click 10 random links from index â¬œ
3. For each link that works, click 2 more links from that page â¬œ
4. Record any broken links

**Expected Pre-Reorg**: âŒ Several broken links expected
**Expected Post-Reorg**: âœ… Zero broken links

**Broken Links Found (Pre)**:
```
1.
2.
3.
...
```

**Broken Links Found (Post)**:
```
[Should be empty]
```

---

### Test 5: Breadth of Coverage â¬œ

**Objective**: Verify all major features are documented and linked.

**Steps**:

Search for these features in `docs/index.md`:

1. Workflows (DEFAULT_WORKFLOW, INVESTIGATION, DDD) â¬œ
2. Core commands (/ultrathink, /analyze, /improve, /fix) â¬œ
3. Agents (architect, builder, tester) â¬œ
4. Goal-seeking agents â¬œ
5. Memory systems (Neo4j) â¬œ
6. Skills â¬œ
7. Remote sessions â¬œ
8. Testing & Quality â¬œ
9. Security â¬œ
10. Troubleshooting â¬œ

**Expected Pre-Reorg**: ğŸŸ¨ Some may be missing or buried
**Expected Post-Reorg**: âœ… All clearly linked

**Coverage Results (Pre)**:
```
Workflows: [âœ…/âŒ]
Commands: [âœ…/âŒ]
Agents: [âœ…/âŒ]
Goal-seeking: [âœ…/âŒ]
Memory: [âœ…/âŒ]
Skills: [âœ…/âŒ]
Remote sessions: [âœ…/âŒ]
Testing: [âœ…/âŒ]
Security: [âœ…/âŒ]
Troubleshooting: [âœ…/âŒ]
```

**Coverage Results (Post)**:
```
Workflows: [âœ…/âŒ]
Commands: [âœ…/âŒ]
Agents: [âœ…/âŒ]
Goal-seeking: [âœ…/âŒ]
Memory: [âœ…/âŒ]
Skills: [âœ…/âŒ]
Remote sessions: [âœ…/âŒ]
Testing: [âœ…/âŒ]
Security: [âœ…/âŒ]
Troubleshooting: [âœ…/âŒ]
```

---

### Test 6: Information Architecture â¬œ

**Objective**: Verify logical grouping and clear hierarchy.

**Steps**:

1. Open `docs/index.md`
2. Are topics grouped logically? (e.g., Getting Started, Core Concepts, etc.) â¬œ
3. Is there a clear hierarchy (H1 â†’ H2 â†’ H3)? â¬œ
4. Are related topics near each other? â¬œ
5. Is there visual separation between major sections? â¬œ

**Expected Pre-Reorg**: ğŸŸ¨ Some organization issues
**Expected Post-Reorg**: âœ… Clear, logical structure

**Observations (Pre)**:
```
[Record observations here]
```

**Observations (Post)**:
```
[Record observations here]
```

---

### Test 7: Search Keywords â¬œ

**Objective**: Verify key terms are findable via browser search (Ctrl+F).

**Steps**:

Open `docs/index.md` and search for:

1. "goal-seeking" or "goal agent" â¬œ
2. "workflow" â¬œ
3. "memory" â¬œ
4. "agent" â¬œ
5. "command" â¬œ
6. "install" â¬œ
7. "troubleshoot" â¬œ

**Expected Pre-Reorg**: ğŸŸ¨ May miss some terms
**Expected Post-Reorg**: âœ… All terms findable

**Search Results (Pre)**:
```
goal-seeking: [Found/Not Found]
workflow: [Found/Not Found]
memory: [Found/Not Found]
agent: [Found/Not Found]
command: [Found/Not Found]
install: [Found/Not Found]
troubleshoot: [Found/Not Found]
```

**Search Results (Post)**:
```
goal-seeking: [Found/Not Found]
workflow: [Found/Not Found]
memory: [Found/Not Found]
agent: [Found/Not Found]
command: [Found/Not Found]
install: [Found/Not Found]
troubleshoot: [Found/Not Found]
```

---

## Post-Reorganization Validation (Expected: All Pass)

After reorganization, re-run ALL tests above and verify:

### Success Criteria

- âœ… All links functional (Test 4)
- âœ… All major features covered (Test 5)
- âœ… New user can get started in â‰¤3 clicks (Test 1)
- âœ… Goal-seeking agents prominently featured (Test 2)
- âœ… All topics accessible in â‰¤3 clicks (Test 3)
- âœ… Logical information architecture (Test 6)
- âœ… All key terms findable (Test 7)

### Final Sign-Off

**Tester Name**: _______________
**Date**: _______________
**Overall Result**: [âœ… PASS / âŒ FAIL]

**Notes**:
```
[Any additional observations or recommendations]
```

---

## Continuous Testing

After initial reorganization, run these tests:

### Weekly Health Check

1. Run automated tests: `pytest tests/docs/test_documentation_structure.py -v`
2. Spot-check 5 random links from index.md
3. Search for one new feature and verify it's linked

### Before Each Release

1. Full automated test suite
2. Complete Manual Test Plan (all 7 tests)
3. User feedback survey (if available)

---

## Troubleshooting Test Failures

### If Links Are Broken

1. Run link validator: `pytest tests/docs/test_documentation_structure.py::TestLinkValidation -v`
2. Check validator output for specific broken links
3. Fix or remove broken links
4. Re-run tests

### If Orphans Found

1. Run orphan detector: `pytest tests/docs/test_documentation_structure.py::TestOrphanDetection -v`
2. For each orphan, either:
   - Add link from relevant parent document
   - Delete if truly obsolete
   - Move to archive/ directory if historical

### If Coverage Missing

1. Run coverage checker: `pytest tests/docs/test_documentation_structure.py::TestDocumentationIntegration::test_feature_coverage -v`
2. Add missing features to index.md
3. Link to detailed documentation
4. Re-run tests

### If Navigation Too Deep

1. Run depth checker: `pytest tests/docs/test_documentation_structure.py::TestDocumentationIntegration::test_navigation_depth -v`
2. For deep documents:
   - Add direct link from index.md or
   - Add link from intermediate document closer to index
3. Re-run tests

---

## Test Execution Log

### Pre-Reorganization Run

**Date**: _______________
**Automated Tests**: [âœ… PASS / âŒ FAIL]
**Manual Tests**: [âœ… PASS / âŒ FAIL]
**Failures**: _______________

### Post-Reorganization Run

**Date**: _______________
**Automated Tests**: [âœ… PASS / âŒ FAIL]
**Manual Tests**: [âœ… PASS / âŒ FAIL]
**Failures**: _______________

---

## Notes for Future Maintainers

1. **These tests should FAIL initially** - that's expected and good!
2. Tests passing means reorganization was successful
3. Run automated tests in CI/CD pipeline
4. Manual tests catch UX issues automation misses
5. Update tests when adding major new features
6. Keep test execution time < 30 seconds
7. Document any test failures in DISCOVERIES.md
