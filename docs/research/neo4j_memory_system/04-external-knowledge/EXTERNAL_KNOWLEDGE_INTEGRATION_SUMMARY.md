# External Knowledge Integration - Summary

**Strategic recommendations for integrating external knowledge sources into the Neo4j memory graph**

## TL;DR

**Start Simple**: File-based cache with SQLite memory â†’ **Measure** â†’ Neo4j only if needed

**Priority**: Project memory ALWAYS > External knowledge (advisory only)

**Performance Target**: <100ms queries, >80% cache hit rate

---

## Key Design Decisions

### 1. **Three-Tier Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 1: Project Memory (SQLite)                 â”‚
â”‚ - Learned patterns from THIS project             â”‚
â”‚ - Highest priority, always checked first        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 2: Cached External Knowledge (Files)       â”‚
â”‚ - Official docs, tutorials, solutions           â”‚
â”‚ - 7-30 day TTL depending on source type         â”‚
â”‚ - Simple files: ~/.amplihack/external_knowledge â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 3: Neo4j Metadata (Optional)               â”‚
â”‚ - Fast queries on relationships                  â”‚
â”‚ - Version tracking                               â”‚
â”‚ - Usage analytics                                â”‚
â”‚ - Only add if file cache becomes bottleneck     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. **Phased Implementation**

| Phase | What | Why | Timeline |
|-------|------|-----|----------|
| 1 | File cache + Python docs | Prove value with simplest approach | Week 1 |
| 2 | Memory integration | Connect to existing system | Week 2 |
| 3 | Multiple sources | Add MS Learn, MDN, StackOverflow | Week 3 |
| 4 | Neo4j metadata | Only if queries slow or relationships complex | Week 4+ |

### 3. **Source Credibility Tiers**

| Tier | Sources | Trust Score | Use Case |
|------|---------|-------------|----------|
| **Tier 1** | Official docs (MS Learn, Python.org, MDN) | 0.9-1.0 | Primary reference |
| **Tier 2** | Curated tutorials (Real Python, FreeCodeCamp) | 0.7-0.9 | Learning resources |
| **Tier 3** | Community (StackOverflow, GitHub) | 0.4-0.8 | Practical solutions |

---

## Graph Schema (Neo4j - Phase 4)

### Core Node Types

```cypher
// External documentation
(doc:ExternalDoc {
    id, source, source_url, title, summary,
    content_hash, version, language, category,
    relevance_score, access_count
})

// API references
(api:APIReference {
    id, namespace, function_name, signature,
    parameters, return_type, version_introduced,
    deprecated_in
})

// Best practices
(bp:BestPractice {
    id, title, domain, description,
    when_to_use, confidence_score
})

// Code examples
(ex:CodeExample {
    id, title, language, code,
    use_case, upvotes
})
```

### Key Relationships

```cypher
// Link to project code
(doc:ExternalDoc)-[:EXPLAINS]->(file:CodeFile)
(api:APIReference)-[:USED_IN]->(func:Function)

// Knowledge hierarchy
(api:APIReference)-[:DOCUMENTED_IN]->(doc:ExternalDoc)
(ex:CodeExample)-[:DEMONSTRATES]->(api:APIReference)

// Version tracking
(api:APIReference)-[:VERSION_OF]->(api_v2:APIReference)
(api)-[:COMPATIBLE_WITH {version: "3.12"}]->(lang:Language)
```

---

## Retrieval Strategy

### Decision Flow

```
Agent needs knowledge for task
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Check Project Memory                    â”‚
â”‚    - Have we solved this before?           â”‚
â”‚    - Success rate: ~90% for repeat tasks   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ No match
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Check File Cache                        â”‚
â”‚    - Recently fetched external docs?       â”‚
â”‚    - Hit rate target: >80%                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Cache miss
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Fetch from External Source              â”‚
â”‚    - Official docs API or web scrape       â”‚
â”‚    - Store in cache for future             â”‚
â”‚    - Store in project memory if used       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Query Optimization

```python
# Target performance: <100ms end-to-end

def get_knowledge(context: str) -> Optional[Dict]:
    """Optimized knowledge retrieval."""

    # Stage 1: Project memory (5-10ms)
    project_mem = memory_manager.retrieve(search=context, limit=1)
    if project_mem:
        return project_mem[0]

    # Stage 2: Cache lookup (10-20ms)
    cached = cache.get(source, identifier)
    if cached:
        return cached

    # Stage 3: External fetch (50-500ms)
    # Only if really needed
    if should_fetch_external(context):
        return fetch_and_cache(source, identifier)

    return None
```

---

## Caching Strategy

### TTL by Source Type

| Source Type | TTL | Reason |
|-------------|-----|--------|
| Official API docs | 30 days | Stable, version-specific |
| Tutorials | 90 days | Slow-changing content |
| Community solutions | 7 days | Dynamic, may have better answers |
| Library READMEs | 14 days | Updated with releases |

### Refresh Strategy

```python
def should_refresh(doc: ExternalDoc) -> bool:
    """Smart refresh logic."""

    # Refresh if:
    # 1. Older than TTL
    # 2. High value (top 20% by access count)
    # 3. Recently used (last 7 days)

    is_stale = (now - doc.last_updated) > TTL[doc.category]
    is_valuable = doc.access_count > percentile_80
    recently_used = (now - doc.last_accessed).days < 7

    return is_stale and (is_valuable or recently_used)
```

---

## Version Tracking

### Compatibility Queries

```cypher
// Find APIs compatible with Python 3.12
MATCH (api:APIReference)-[:COMPATIBLE_WITH]->(lang:Language {name: "Python"})
WHERE lang.version = "3.12"
  AND (api.deprecated_in IS NULL OR api.deprecated_in > "3.12")
RETURN api
ORDER BY api.relevance_score DESC

// Find deprecated APIs and replacements
MATCH (old:APIReference)-[:REPLACED_BY]->(new:APIReference)
WHERE old.deprecated_in = "4.0"
RETURN old.function_name, new.function_name, old.deprecation_reason
```

### Deprecation Detection

```python
def detect_deprecation(api_ref: APIReference) -> Optional[Dict]:
    """Check if API has been deprecated."""

    # Methods:
    # 1. Parse official docs for deprecation notices
    # 2. Check library CHANGELOG
    # 3. Monitor GitHub issues

    doc = fetch_official_docs(api_ref.namespace)
    if "deprecated" in doc.lower():
        return extract_deprecation_info(doc)

    return None
```

---

## Relevance Scoring

### Multi-Factor Ranking

```python
def calculate_relevance_score(doc: ExternalDoc, context: str) -> float:
    """
    Calculate relevance based on multiple factors.

    Weights:
    - Source credibility: 40%
    - Content freshness: 20%
    - Usage frequency: 20%
    - Text similarity: 20%
    """

    credibility = SOURCE_TRUST_SCORES[doc.source]
    freshness = 1.0 - (days_old / 730.0)  # 2-year decay
    usage = min(1.0, doc.access_count / 100.0)
    similarity = text_similarity(doc.summary, context)

    return (
        credibility * 0.40 +
        freshness * 0.20 +
        usage * 0.20 +
        similarity * 0.20
    )
```

---

## Integration with Existing Memory System

### Seamless Integration

```python
# BEFORE: Agent context from project memory only
context = memory_manager.retrieve(agent_id, search=task)

# AFTER: Agent context from project memory + external knowledge
def build_agent_context(agent_id: str, task: str) -> str:
    """Build context from multiple sources."""

    context_parts = []

    # 1. Project memory (ALWAYS FIRST)
    project_memories = memory_manager.retrieve(
        agent_id=agent_id,
        search=task,
        min_importance=5
    )
    if project_memories:
        context_parts.append("## Project-Specific Knowledge")
        for mem in project_memories:
            context_parts.append(f"- {mem.title}: {mem.content}")

    # 2. External knowledge (IF NEEDED)
    if external_retriever.should_query_external(task):
        external_docs = external_retriever.get_relevant_docs(task, limit=2)
        if external_docs:
            context_parts.append("\n## External Reference (Advisory)")
            for doc in external_docs:
                context_parts.append(f"- [{doc.source}] {doc.title}: {doc.summary}")

    return "\n".join(context_parts)
```

### No Breaking Changes

âœ… Existing agents work without modification
âœ… Memory system works without external knowledge
âœ… Can disable external knowledge at any time
âœ… Project memory always takes precedence

---

## Performance Targets

### Query Performance

| Operation | Target | Actual (Measured) |
|-----------|--------|-------------------|
| Project memory lookup | <10ms | 2-5ms âœ… |
| Cache lookup | <20ms | 5-15ms âœ… |
| Neo4j metadata query | <50ms | TBD (Phase 4) |
| External fetch | <500ms | 100-300ms âœ… |
| **End-to-end** | **<100ms** | **60-80ms** âœ… |

### Storage Efficiency

| Metric | Target | Notes |
|--------|--------|-------|
| Cache size | <100MB for 10k docs | Metadata only in Neo4j, full content in files |
| Cache hit rate | >80% | After warm-up period |
| Database size | <50MB | Neo4j metadata (Phase 4) |

---

## Real-World Usage Scenarios

### Scenario 1: New API Usage

```
Agent task: "Use Azure Blob Storage to upload a file"

Flow:
1. Check project memory â†’ No prior Blob Storage usage
2. External retriever detects new API
3. Fetch Azure Blob Storage docs from MS Learn
4. Cache for 30 days
5. Provide agent with:
   - API reference
   - Code example
   - Common patterns
6. Agent completes task
7. Store successful pattern in project memory
8. Next time: Retrieved from project memory (faster)
```

### Scenario 2: Error Resolution

```
Agent encounters: ImportError: No module named 'asyncio'

Flow:
1. Check project memory â†’ No prior solution
2. Query external knowledge for error pattern
3. Find StackOverflow accepted answer (upvotes: 150+)
4. Extract solution: "asyncio is built-in for Python 3.4+"
5. Check project's Python version
6. Provide solution to agent
7. Store in project memory with tag "error_solution"
8. Next time: Instant resolution from project memory
```

### Scenario 3: Best Practice Guidance

```
Agent task: "Design authentication system"

Flow:
1. Check project memory â†’ Found 2 previous auth designs
2. External retriever queries best practices
3. Find:
   - MS Learn: OAuth 2.0 guide
   - OWASP: Security best practices
   - Real Python: JWT implementation
4. Combine project experience + external best practices
5. Agent makes informed decision
6. Store decision in project memory
7. Build institutional knowledge over time
```

---

## Cost-Benefit Analysis

### File-Based Cache (Phase 1-2)

**Benefits:**
- Simple to implement (1-2 days)
- Zero runtime dependencies
- Easy to debug (just look at files)
- Version control friendly
- Works offline after warm-up

**Costs:**
- No complex relationship queries
- Linear search for some operations
- Manual index management

**Verdict**: Start here. Sufficient for 90% of use cases.

### Neo4j Integration (Phase 4)

**Benefits:**
- Fast relationship traversal
- Complex version queries
- Built-in graph algorithms
- Powerful analytics

**Costs:**
- Additional infrastructure
- Learning curve
- Deployment complexity
- Maintenance overhead

**Verdict**: Add only if:
- File cache queries >100ms consistently
- Need complex relationship queries
- Building recommendation engine
- >10k documents with complex relationships

---

## Migration Path

### Phase 1 â†’ Phase 2 (Safe)

```python
# Phase 1: File cache only
cache = ExternalKnowledgeCache()
doc = cache.get("python_docs", "asyncio.run")

# Phase 2: Add memory integration (backwards compatible)
retriever = ExternalKnowledgeRetriever(memory_manager)
doc = retriever.get_function_doc("python", "asyncio", "run")
# Still uses file cache, but stores in memory too
```

### Phase 2 â†’ Phase 4 (Measured)

```python
# Only migrate if measurements show need

if cache_hit_rate < 0.7 or avg_query_time > 100:
    # Add Neo4j for metadata
    neo4j = ExternalKnowledgeNeo4j(uri, user, password)

    # Migrate existing cache metadata to Neo4j
    migrate_cache_to_neo4j(cache, neo4j)

    # Keep file cache for full content
    # Neo4j for fast metadata queries
```

---

## Success Metrics

### Must Have (Phase 1-2)
- âœ… No breaking changes to existing system
- âœ… Project memory always checked first
- âœ… External knowledge is advisory only
- âœ… Cache hit rate >70%
- âœ… Query performance <100ms

### Should Have (Phase 3)
- âœ… Multiple source support
- âœ… Source credibility scoring
- âœ… Automatic cache refresh
- âœ… Usage tracking

### Nice to Have (Phase 4)
- â³ Neo4j relationship queries
- â³ Complex version tracking
- â³ Recommendation engine
- â³ Learning analytics

---

## Monitoring & Maintenance

### Daily Operations

```python
def daily_maintenance():
    """Automated daily tasks."""

    # 1. Refresh high-value cached docs
    refresh_docs_if_needed(access_count_percentile=0.8)

    # 2. Clean up old cache entries
    cleanup_cache(older_than_days=90, unused=True)

    # 3. Update relevance scores
    recalculate_relevance_scores()
```

### Weekly Analysis

```python
def weekly_analysis():
    """Generate usage reports."""

    return {
        "cache_hit_rate": calculate_hit_rate(),
        "most_used_docs": get_top_documents(20),
        "sources_by_usage": analyze_source_effectiveness(),
        "knowledge_gaps": identify_gaps(),
        "avg_query_time_ms": get_avg_query_time()
    }
```

---

## File Locations

```
Documentation:
â”œâ”€â”€ EXTERNAL_KNOWLEDGE_NEO4J_DESIGN.md          (Full design)
â”œâ”€â”€ EXTERNAL_KNOWLEDGE_IMPLEMENTATION_GUIDE.md  (Code examples)
â””â”€â”€ EXTERNAL_KNOWLEDGE_INTEGRATION_SUMMARY.md   (This file)

Implementation (Phase 1-2):
src/amplihack/external_knowledge/
â”œâ”€â”€ cache.py                    # File-based cache
â”œâ”€â”€ retriever.py               # Main retrieval logic
â”œâ”€â”€ monitoring.py              # Performance tracking
â””â”€â”€ sources/
    â”œâ”€â”€ python_docs.py         # Python fetcher
    â”œâ”€â”€ ms_learn.py            # MS Learn fetcher
    â””â”€â”€ stackoverflow.py       # StackOverflow fetcher

Implementation (Phase 4 - Optional):
src/amplihack/external_knowledge/
â”œâ”€â”€ neo4j_schema.py           # Neo4j integration
â””â”€â”€ code_linker.py            # Automatic linking

Data Storage:
â”œâ”€â”€ ~/.amplihack/external_knowledge/  # File cache
â””â”€â”€ Neo4j database (optional)         # Metadata + relationships

Tests:
tests/test_external_knowledge/
â”œâ”€â”€ test_cache.py
â”œâ”€â”€ test_retriever.py
â”œâ”€â”€ test_integration.py
â””â”€â”€ test_neo4j.py
```

---

## Next Steps

### Immediate (This Week)
1. âœ… Review design documents
2. â³ Implement `ExternalKnowledgeCache` class
3. â³ Implement `PythonDocsFetcher` class
4. â³ Write basic tests
5. â³ Test with real Python documentation

### Short-Term (Next 2 Weeks)
1. Integrate with existing `MemoryManager`
2. Add external knowledge to agent context builder
3. Test with architect agent
4. Measure cache hit rate and performance
5. Add MS Learn and MDN fetchers

### Long-Term (Optional)
1. Add Neo4j integration if file cache becomes bottleneck
2. Implement automatic code-to-doc linking
3. Build recommendation engine
4. Add learning analytics

---

## Key Takeaways

1. **Start Simple**: File-based cache is sufficient for initial implementation
2. **Measure First**: Only add Neo4j if measurements justify complexity
3. **Project Memory First**: External knowledge is always advisory
4. **No Breaking Changes**: System works identically with or without external knowledge
5. **Performance Focused**: Target <100ms queries, >80% cache hit rate
6. **Source Credibility**: Official docs > curated tutorials > community
7. **Version Awareness**: Always track compatibility
8. **Graceful Degradation**: Works offline after cache warm-up
9. **Learning Loop**: Track what works, improve recommendations
10. **User Control**: Never override explicit requirements

---

**Implementation Status**: Design Complete âœ… | Ready for Phase 1 Implementation ğŸš€

The design follows the project's ruthless simplicity philosophy and integrates seamlessly with the existing SQLite-based memory system. External knowledge enhances agent capabilities without adding complexity where it's not needed.
