# Final Synthesis: Unified Memory & Knowledge Graph Architecture

**Date**: November 2, 2025
**Status**: Complete Architecture Vision - Ready for Implementation
**Research Integration**: Neo4j Memory + Knowledge Graph + blarify Code Graph

---

## Executive Summary

This document synthesizes three major research streams into a unified, actionable architecture for amplihack's memory and knowledge system. The result is a **single Neo4j-based unified temporal knowledge graph** that combines:

1. **Episodic Memory** (what happened) - Agent experiences and actions
2. **Semantic Knowledge** (what is known) - Facts, documentation, patterns
3. **Code Structure** (what exists) - blarify code graph integration

**Key Decision**: Build Neo4j from Day 1, not SQLite-first, because:
- Graph database is MANDATORY for code graph integration (user requirement)
- 20% faster implementation, 67% simpler queries, 60% less maintenance
- Break-even in Month 1 despite additional setup complexity
- Enables agent type memory sharing (user requirement)

**Timeline**: 4-5 months for full system (27-35 hours Phase 1, 58-78 hours Phase 2, 4-5 hours Phase 3)

---

## 1. Integrated Architecture Vision

### 1.1 The Three-Subgraph Unified Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Agent Layer                                  â”‚
â”‚  [Architect] [Builder] [Reviewer] [Tester] [Knowledge Builder]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Neo4j Unified Temporal Knowledge Graph                     â”‚
â”‚                   (Single Database Instance)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ EPISODIC SUBGRAPH   â”‚  â”‚ SEMANTIC SUBGRAPH   â”‚                  â”‚
â”‚  â”‚ (Memory System)     â”‚  â”‚ (Knowledge Builder) â”‚                  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
â”‚  â”‚ Nodes:              â”‚  â”‚ Nodes:              â”‚                  â”‚
â”‚  â”‚ â€¢ AgentType         â”‚  â”‚ â€¢ Concept           â”‚                  â”‚
â”‚  â”‚ â€¢ Project           â”‚  â”‚ â€¢ Documentation     â”‚                  â”‚
â”‚  â”‚ â€¢ Memory            â”‚  â”‚ â€¢ Pattern           â”‚                  â”‚
â”‚  â”‚ â€¢ Episode           â”‚  â”‚ â€¢ BestPractice      â”‚                  â”‚
â”‚  â”‚                     â”‚  â”‚ â€¢ KnowledgeFact     â”‚                  â”‚
â”‚  â”‚ Relationships:      â”‚  â”‚ â€¢ KnowledgeGraph    â”‚                  â”‚
â”‚  â”‚ â€¢ HAS_MEMORY        â”‚  â”‚                     â”‚                  â”‚
â”‚  â”‚ â€¢ CONTAINS_MEMORY   â”‚  â”‚ Relationships:      â”‚                  â”‚
â”‚  â”‚ â€¢ CREATED_BY        â”‚  â”‚ â€¢ IS_A              â”‚                  â”‚
â”‚  â”‚ â€¢ IN_PROJECT        â”‚  â”‚ â€¢ DOCUMENTED_BY     â”‚                  â”‚
â”‚  â”‚                     â”‚  â”‚ â€¢ APPLIES_TO        â”‚                  â”‚
â”‚  â”‚                     â”‚  â”‚ â€¢ RECOMMENDS        â”‚                  â”‚
â”‚  â”‚                     â”‚  â”‚ â€¢ KNOWLEDGE_FACT    â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚           â”‚                         â”‚                               â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                    â”‚                                                â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚
â”‚           â”‚  CODE SUBGRAPH   â”‚                                      â”‚
â”‚           â”‚  (blarify+SCIP)  â”‚                                      â”‚
â”‚           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                      â”‚
â”‚           â”‚ Nodes:           â”‚                                      â”‚
â”‚           â”‚ â€¢ CodeFile       â”‚                                      â”‚
â”‚           â”‚ â€¢ Function       â”‚                                      â”‚
â”‚           â”‚ â€¢ Class          â”‚                                      â”‚
â”‚           â”‚ â€¢ Module         â”‚                                      â”‚
â”‚           â”‚ â€¢ CodePattern    â”‚                                      â”‚
â”‚           â”‚                  â”‚                                      â”‚
â”‚           â”‚ Relationships:   â”‚                                      â”‚
â”‚           â”‚ â€¢ CONTAINS       â”‚                                      â”‚
â”‚           â”‚ â€¢ CALLS          â”‚                                      â”‚
â”‚           â”‚ â€¢ INHERITS       â”‚                                      â”‚
â”‚           â”‚ â€¢ IMPORTS        â”‚                                      â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ BRIDGE RELATIONSHIPS (Cross-Subgraph Connections)              â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ Episodic â†” Semantic:                                           â”‚ â”‚
â”‚  â”‚  â€¢ (:Episode)-[:DEMONSTRATES]->(:Pattern)                      â”‚ â”‚
â”‚  â”‚  â€¢ (:Episode)-[:APPLIES]->(:BestPractice)                      â”‚ â”‚
â”‚  â”‚  â€¢ (:Memory)-[:ABOUT]->(:Concept)                              â”‚ â”‚
â”‚  â”‚  â€¢ (:KnowledgeFact)-[:DERIVED_FROM]->(:Episode)                â”‚ â”‚
â”‚  â”‚                                                                 â”‚ â”‚
â”‚  â”‚ Episodic â†” Code:                                               â”‚ â”‚
â”‚  â”‚  â€¢ (:Episode)-[:MODIFIED]->(:CodeFile)                         â”‚ â”‚
â”‚  â”‚  â€¢ (:Memory)-[:REFERENCES]->(:Function)                        â”‚ â”‚
â”‚  â”‚  â€¢ (:Episode)-[:WORKED_ON]->(:Function)                        â”‚ â”‚
â”‚  â”‚                                                                 â”‚ â”‚
â”‚  â”‚ Semantic â†” Code:                                               â”‚ â”‚
â”‚  â”‚  â€¢ (:Function)-[:IMPLEMENTS]->(:Pattern)                       â”‚ â”‚
â”‚  â”‚  â€¢ (:Function)-[:DOCUMENTED_BY]->(:Documentation)              â”‚ â”‚
â”‚  â”‚  â€¢ (:CodePattern)-[:IS_INSTANCE_OF]->(:Pattern)                â”‚ â”‚
â”‚  â”‚  â€¢ (:Function)-[:ABOUT]->(:Concept)                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Unified Query Interface                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Cross-Layer Queries:                                                 â”‚
â”‚  â€¢ "Find times we successfully used Factory pattern"                 â”‚
â”‚  â€¢ "Show documentation for functions modified last week"             â”‚
â”‚  â€¢ "What knowledge did we learn from authentication errors?"         â”‚
â”‚  â€¢ "Get context for implementing OAuth" (memory + knowledge + code)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Component Responsibilities

**Episodic Subgraph (Memory System)**
- **Purpose**: Record agent experiences, decisions, and outcomes
- **Managed By**: Memory system (phase 1 implementation)
- **Update Pattern**: Real-time during agent execution
- **Retention**: Project-scoped with global/project/instance levels
- **Key Feature**: Agent type memory sharing (architects share with architects)

**Semantic Subgraph (Knowledge Builder)**
- **Purpose**: Store facts, documentation, patterns, best practices
- **Managed By**: Knowledge builder agent + web search
- **Update Pattern**: Batch updates when building knowledge graphs
- **Retention**: Permanent with confidence scoring and temporal validity
- **Key Feature**: Confidence-weighted retrieval, source tracking

**Code Subgraph (blarify)**
- **Purpose**: AST-based code structure and relationships
- **Managed By**: blarify + SCIP indexing
- **Update Pattern**: Incremental on code changes
- **Retention**: Follows project codebase
- **Key Feature**: 330x faster than LSP, multi-language support

**Bridge Relationships**
- **Purpose**: Connect experiences to knowledge to code
- **Managed By**: All three systems cooperatively
- **Key Benefit**: Enable cross-layer queries that span subgraphs
- **Example**: "Show me all times we successfully applied this pattern to this type of function"

---

## 2. Lessons from Research Streams

### 2.1 From Neo4j Memory System Research

**What We Adopt**:
- âœ… **Neo4j from Day 1**: Graph database is technically superior and user-required
- âœ… **Three-Level Hierarchy**: Global, Project, Instance memory scopes
- âœ… **Agent Type Singletons**: AgentType nodes enable agent type memory sharing
- âœ… **Multi-Dimensional Quality**: 6-dimension scoring (confidence, validation, recency, consensus, context, impact)
- âœ… **Hybrid Conflict Resolution**: 70% auto, 25% debate, 5% human
- âœ… **Single Database**: One Neo4j instance with project namespacing
- âœ… **No ORM**: Direct Cypher queries align with zero-BS philosophy

**What We Improve**:
- ðŸ”„ **Unify with Knowledge**: Don't separate memory and knowledge systems
- ðŸ”„ **Add Temporal Model**: Use Graphiti bi-temporal pattern for validity tracking
- ðŸ”„ **Cross-Subgraph Bridges**: Explicit relationships connecting all three subgraphs
- ðŸ”„ **Learning Loop**: Automatic episodic â†’ semantic promotion after repetition

**Why Neo4j Wins Over SQLite**:

| Dimension | Winner | Margin | One-Time vs Continuous |
|-----------|--------|--------|------------------------|
| Setup Complexity | SQLite | 50-60 min | ONE-TIME COST |
| Implementation | Neo4j | 8-13 hours (20%) | CONTINUOUS BENEFIT |
| Query Complexity | Neo4j | 67% simpler | CONTINUOUS BENEFIT |
| Maintenance | Neo4j | 60-75% less | CONTINUOUS BENEFIT |
| Code Graph Integration | Neo4j | 12-15 hours saved | ONE-TIME + CONTINUOUS |
| Break-Even | Neo4j | Month 1 | ECONOMICS WIN |
| 12-Month ROI | Neo4j | 47% savings | LONG-TERM WIN |

**Verdict**: Setup complexity is one-time pain, query simplicity is forever. Neo4j wins decisively.

### 2.2 From Knowledge Graph Systems Research

**What We Adopt**:
- âœ… **Graphiti/Zep Pattern**: Temporal knowledge graph with 94.8% accuracy
- âœ… **Unified Architecture**: One graph for memory + knowledge, not separate systems
- âœ… **Neo4j LLM Builder**: For document ingestion (PDFs, web, video)
- âœ… **Three-Stage Pipeline**: Extract entities â†’ Extract relationships â†’ Integrate
- âœ… **Hybrid Extraction**: Traditional NLP + LLM for robust extraction
- âœ… **Source Tracking**: Every fact tracks origin, timestamp, confidence, sources
- âœ… **Quality Control**: Multi-agent validation + confidence scoring + temporal validation

**What We Improve**:
- ðŸ”„ **Claude Integration**: Use Claude 3.5 Sonnet (already integrated) instead of generic LLM
- ðŸ”„ **Amplihack Workflow**: Integrate with existing agent system, not standalone
- ðŸ”„ **Code-First**: Integrate code graph (blarify) as first-class subgraph
- ðŸ”„ **Incremental Updates**: Real-time updates like Graphiti, not batch-only

**Admiral-KG Recommendation**:
- âŒ No public "admiral-kg" repository found
- âœ… Use **Graphiti/Zep** as functional equivalent (temporal architecture, proven performance)
- âœ… Use **Neo4j LLM Builder** for document ingestion
- âœ… Use **LangChain Neo4j** if need multiple LLM providers

### 2.3 From Microsoft Amplifier Analysis

**What This Synthesis Provides That Amplifier Lacks**:
- âœ… **Native Graph**: Real relationships vs JSON key-value storage
- âœ… **Scalability**: Neo4j handles millions of nodes vs ~10k memory limit
- âœ… **Cross-Layer Queries**: Traverse memory + knowledge + code vs isolated lookups
- âœ… **Deduplication**: Graph-native vs content hashing workarounds
- âœ… **Agent Type Sharing**: First-class vs manual memory routing

**What We Keep from Amplifier's Simplicity**:
- âœ… **Hook-Based Extraction**: Extract at agent lifecycle boundaries
- âœ… **Metadata-Rich**: Source, confidence, timestamps for every memory
- âœ… **Tag-Based Organization**: Labels and properties for retrieval
- âœ… **Advisory Only**: Memory never prescriptive, always suggestive
- âœ… **Graceful Degradation**: System works if memory unavailable

---

## 3. Knowledge vs Memory Distinction

### 3.1 Clear Definitions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EPISODIC MEMORY (Experiential)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Question: "What happened?"                                       â”‚
â”‚                                                                  â”‚
â”‚ Characteristics:                                                 â”‚
â”‚  â€¢ Time-bound events                                             â”‚
â”‚  â€¢ Agent-specific experiences                                    â”‚
â”‚  â€¢ Task outcomes (success/failure)                               â”‚
â”‚  â€¢ Conversation history                                          â”‚
â”‚  â€¢ Decision rationale                                            â”‚
â”‚                                                                  â”‚
â”‚ Examples:                                                        â”‚
â”‚  â€¢ "On Nov 1, architect agent designed auth system using JWT"   â”‚
â”‚  â€¢ "User prefers verbose logging with timestamps"               â”‚
â”‚  â€¢ "Last commit failed due to pre-commit hook (ruff error)"     â”‚
â”‚  â€¢ "Builder agent tried approach X, failed, then succeeded with Y" â”‚
â”‚                                                                  â”‚
â”‚ Storage:                                                         â”‚
â”‚  â€¢ Episode nodes with timestamps                                 â”‚
â”‚  â€¢ Links to AgentType, Project, Memory                           â”‚
â”‚  â€¢ Outcome tracking (success/failure)                            â”‚
â”‚  â€¢ Context preservation (what, why, how)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SEMANTIC KNOWLEDGE (Factual)                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Question: "What is known?"                                       â”‚
â”‚                                                                  â”‚
â”‚ Characteristics:                                                 â”‚
â”‚  â€¢ Timeless facts                                                â”‚
â”‚  â€¢ Domain knowledge                                              â”‚
â”‚  â€¢ API documentation                                             â”‚
â”‚  â€¢ Best practices                                                â”‚
â”‚  â€¢ Design patterns                                               â”‚
â”‚                                                                  â”‚
â”‚ Examples:                                                        â”‚
â”‚  â€¢ "Python uses indentation for block structure"                â”‚
â”‚  â€¢ "REST APIs typically use JSON for data exchange"             â”‚
â”‚  â€¢ "JWT tokens expire after configured timeout"                 â”‚
â”‚  â€¢ "Factory pattern creates objects without specifying class"   â”‚
â”‚                                                                  â”‚
â”‚ Storage:                                                         â”‚
â”‚  â€¢ Concept nodes (entities)                                      â”‚
â”‚  â€¢ KnowledgeFact relationships (triplets)                        â”‚
â”‚  â€¢ Documentation nodes (with URLs)                               â”‚
â”‚  â€¢ Pattern nodes (with success rates)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 How They Complement Each Other

**Scenario 1: Implementing Authentication**

```cypher
// Query: "Get context for implementing OAuth authentication"

// 1. SEMANTIC: Find knowledge about OAuth
MATCH (oauth:Concept {name: "OAuth"})
OPTIONAL MATCH (oauth)-[:DOCUMENTED_BY]->(doc:Documentation)
OPTIONAL MATCH (oauth)<-[:APPLIES_TO]-(pattern:Pattern)
// Result: OAuth concept, documentation links, applicable patterns

// 2. EPISODIC: Find past experiences with OAuth
MATCH (e:Episode)-[:INVOLVED_CONCEPT]->(oauth)
WHERE e.outcome = "success"
OPTIONAL MATCH (e)-[:APPLIED_PATTERN]->(p:Pattern)
// Result: Past successful implementations, what patterns worked

// 3. CODE: Find existing OAuth implementations
MATCH (f:Function)-[:ABOUT]->(oauth)
OPTIONAL MATCH (f)-[:IMPLEMENTS]->(pattern)
// Result: Existing OAuth functions, what patterns they implement

// 4. SYNTHESIZE: Combine all three
RETURN {
  knowledge: collect(DISTINCT {doc: doc.url, pattern: pattern.name}),
  experiences: collect(DISTINCT {when: e.timestamp, approach: e.approach}),
  code_examples: collect(DISTINCT {function: f.name, file: f.file_path})
}
```

**Result**: Agent gets documentation (semantic), learns from past attempts (episodic), and sees existing code (code graph) - comprehensive context from all three subgraphs.

**Scenario 2: Learning from Repetition**

```cypher
// Query: "Extract patterns from repeated successful experiences"

MATCH (e:Episode)-[:USED_APPROACH]->(a:Approach)
WHERE e.outcome = "success"
WITH a, count(e) as success_count, collect(e) as episodes
WHERE success_count >= 3

// PROMOTE to semantic knowledge
CREATE (k:KnowledgeFact {
  subject: a.name,
  predicate: "RECOMMENDED_FOR",
  object: a.use_case,
  confidence: success_count / 10.0,  // More successes = higher confidence
  derived_from: "experience",
  evidence_count: success_count
})

// LINK to supporting episodes
UNWIND episodes as episode
CREATE (k)-[:GROUNDED_IN]->(episode)

RETURN k.subject, k.object, k.confidence, success_count
```

**Result**: Episodic memories (what happened) automatically become semantic knowledge (what is known) after sufficient repetition. Memory system teaches itself.

### 3.3 Query Patterns for Combined Use

**Pattern 1: Knowledge-Grounded Decisions**

```cypher
// "Should I use JWT for this auth system?"

// Semantic: What do we know?
MATCH (jwt:Concept {name: "JWT"})
MATCH (jwt)-[f:KNOWLEDGE_FACT]->()
WITH collect({fact: f.predicate + " " + f.object, confidence: f.confidence}) as knowledge

// Episodic: What's our experience?
MATCH (e:Episode)-[:INVOLVED_CONCEPT]->(jwt)
WITH knowledge,
     count(CASE WHEN e.outcome = "success" THEN 1 END) as successes,
     count(CASE WHEN e.outcome = "failure" THEN 1 END) as failures

RETURN {
  documented_knowledge: knowledge,
  success_rate: successes * 1.0 / (successes + failures),
  recommendation: CASE
    WHEN successes * 1.0 / (successes + failures) > 0.7 THEN "Recommended"
    ELSE "Proceed with caution"
  END
}
```

**Pattern 2: Error Analysis with Knowledge**

```cypher
// "Why did JWT validation fail?"

// Episodic: Find the error
MATCH (e:Episode)
WHERE e.description CONTAINS "JWT" AND e.error IS NOT NULL

// Semantic: What do we know about JWT errors?
MATCH (jwt:Concept {name: "JWT"})-[:DOCUMENTED_BY]->(doc:Documentation)
WHERE doc.content CONTAINS "error" OR doc.content CONTAINS "troubleshooting"

// Code: What functions are involved?
MATCH (e)-[:WORKED_ON]->(f:Function)
MATCH (f)-[:ABOUT]->(jwt)

RETURN {
  error_episode: e.error,
  error_timestamp: e.timestamp,
  relevant_docs: collect(DISTINCT doc.url),
  involved_functions: collect(DISTINCT f.name),
  resolution: e.resolution
}
```

**Pattern 3: Code + Documentation + Experience**

```cypher
// "Comprehensive context for modifying this function"

MATCH (f:Function {name: $function_name})

// Code: What does it do?
OPTIONAL MATCH (f)-[:CALLS]->(called:Function)
OPTIONAL MATCH (f)-[:IMPLEMENTS]->(pattern:Pattern)

// Semantic: Documentation
OPTIONAL MATCH (f)-[:ABOUT]->(concept:Concept)
OPTIONAL MATCH (concept)-[:DOCUMENTED_BY]->(doc:Documentation)

// Episodic: Past modifications
OPTIONAL MATCH (e:Episode)-[:MODIFIED]->(cf:CodeFile)-[:CONTAINS]->(f)

RETURN {
  function_info: {name: f.name, file: f.file_path, pattern: pattern.name},
  calls: collect(DISTINCT called.name),
  documentation: collect(DISTINCT {concept: concept.name, doc: doc.url}),
  past_changes: collect(DISTINCT {
    when: e.timestamp,
    agent: e.agent_id,
    outcome: e.outcome,
    approach: e.approach
  })
}
```

---

## 4. Three-Subgraph Architecture Details

### 4.1 Schema Design

**Episodic Subgraph Schema**:

```cypher
// Node Types
CREATE CONSTRAINT agent_type_unique FOR (at:AgentType) REQUIRE at.id IS UNIQUE;
CREATE CONSTRAINT project_unique FOR (p:Project) REQUIRE p.id IS UNIQUE;
CREATE CONSTRAINT memory_unique FOR (m:Memory) REQUIRE m.id IS UNIQUE;
CREATE CONSTRAINT episode_unique FOR (e:Episode) REQUIRE e.id IS UNIQUE;

// Indexes for Performance
CREATE INDEX memory_importance FOR (m:Memory) ON (m.importance);
CREATE INDEX memory_created FOR (m:Memory) ON (m.created_at);
CREATE INDEX episode_timestamp FOR (e:Episode) ON (e.timestamp);
CREATE INDEX episode_outcome FOR (e:Episode) ON (e.outcome);

// Node Properties
(:AgentType {
  id: "architect",
  name: "Architect Agent",
  description: "System design and architecture"
})

(:Project {
  id: "uuid",
  name: "ProjectX",
  created_at: datetime()
})

(:Memory {
  id: "uuid",
  memory_type: "conversation|decision|pattern|preference",
  title: "Brief title",
  content: "Full content",
  importance: 0.0-1.0,
  created_at: datetime(),
  memory_level: "global|project|instance"
})

(:Episode {
  id: "uuid",
  description: "What was done",
  approach: "How it was done",
  outcome: "success|failure",
  error: "Error message if failure",
  resolution: "How it was fixed",
  timestamp: datetime()
})

// Relationship Types
(:AgentType)-[:HAS_MEMORY]->(:Memory)
(:Project)-[:CONTAINS_MEMORY]->(:Memory)
(:Episode)-[:CREATED_BY]->(:AgentType)
(:Episode)-[:IN_PROJECT]->(:Project)
```

**Semantic Subgraph Schema**:

```cypher
// Node Types
CREATE CONSTRAINT concept_unique FOR (c:Concept) REQUIRE c.name IS UNIQUE;
CREATE CONSTRAINT doc_unique FOR (d:Documentation) REQUIRE d.url IS UNIQUE;
CREATE INDEX pattern_name FOR (p:Pattern) ON (p.name);
CREATE INDEX knowledge_confidence FOR (k:KnowledgeFact) ON (k.confidence);

// Node Properties
(:Concept {
  name: "OAuth",
  description: "Open authorization standard",
  first_seen: datetime()
})

(:Documentation {
  url: "https://oauth.net/2/",
  content: "Full doc content or summary",
  credibility: 0.0-1.0,
  last_updated: datetime(),
  source_type: "official|community|example"
})

(:Pattern {
  name: "Factory Pattern",
  description: "Creates objects without specifying exact class",
  success_rate: 0.0-1.0,  // Based on episodic evidence
  use_cases: ["object creation", "dependency injection"]
})

(:BestPractice {
  name: "Input validation",
  content: "Always validate user input before processing",
  confidence: 0.0-1.0,
  domain: "security|performance|maintainability"
})

(:KnowledgeFact {
  subject: "Python",
  predicate: "HAS_VERSION",
  object: "3.12",
  confidence: 0.0-1.0,
  source_question: "What's the latest Python version?",
  source_answer: "Full answer text",
  extracted_at: datetime()
})

// Relationship Types
(:Concept)-[:IS_A]->(:Concept)  // "JWT" IS_A "Security Token"
(:Concept)-[:DOCUMENTED_BY]->(:Documentation)
(:Pattern)-[:APPLIES_TO]->(:Concept)
(:BestPractice)-[:RECOMMENDS]->(:Pattern)
(:Concept)-[:KNOWLEDGE_FACT {predicate, confidence}]->(:Concept)
(:KnowledgeGraph)-[:CONTAINS_FACT]->(:KnowledgeFact)
```

**Code Subgraph Schema** (from blarify):

```cypher
// Node Types
CREATE INDEX code_file_path FOR (cf:CodeFile) ON (cf.path);
CREATE INDEX function_name FOR (f:Function) ON (f.name);
CREATE INDEX code_pattern_hash FOR (cp:CodePattern) ON (cp.signature_hash);

// Node Properties
(:CodeFile {
  path: "/src/auth.py",
  language: "python",
  last_modified: datetime(),
  lines: 150
})

(:Function {
  name: "authenticate_user",
  signature: "def authenticate_user(username: str, password: str) -> User",
  file_path: "/src/auth.py",
  start_line: 45,
  end_line: 62,
  complexity: 5  // Cyclomatic complexity
})

(:Class {
  name: "UserManager",
  file_path: "/src/auth.py",
  start_line: 10,
  end_line: 100
})

(:Module {
  name: "auth",
  path: "/src/auth.py",
  imports: ["jwt", "bcrypt", "datetime"]
})

(:CodePattern {
  name: "JWT token validation",
  signature_hash: "hash_of_pattern",  // For deduplication across projects
  pattern_type: "security|error_handling|data_access"
})

// Relationship Types
(:CodeFile)-[:CONTAINS]->(:Function)
(:CodeFile)-[:CONTAINS]->(:Class)
(:Function)-[:CALLS]->(:Function)
(:Class)-[:INHERITS]->(:Class)
(:Module)-[:IMPORTS]->(:Module)
(:Function)-[:MATCHES]->(:CodePattern)
```

### 4.2 Bridge Relationships

**Episodic â†” Semantic Bridges**:

```cypher
// Episode demonstrates pattern
(:Episode)-[:DEMONSTRATES {
  how: "specific approach taken",
  outcome: "success|failure"
}]->(:Pattern)

// Episode applies best practice
(:Episode)-[:APPLIES {
  adherence: 0.0-1.0
}]->(:BestPractice)

// Memory about concept
(:Memory)-[:ABOUT {
  relevance: 0.0-1.0
}]->(:Concept)

// Knowledge fact derived from episodes
(:KnowledgeFact)-[:DERIVED_FROM {
  evidence_count: N
}]->(:Episode)
```

**Episodic â†” Code Bridges**:

```cypher
// Episode modified code
(:Episode)-[:MODIFIED {
  change_type: "create|update|delete",
  lines_changed: N
}]->(:CodeFile)

// Memory references function
(:Memory)-[:REFERENCES {
  context: "why this function matters"
}]->(:Function)

// Episode worked on function
(:Episode)-[:WORKED_ON {
  duration_minutes: N,
  complexity_impact: "+5|-3"
}]->(:Function)
```

**Semantic â†” Code Bridges**:

```cypher
// Function implements pattern
(:Function)-[:IMPLEMENTS {
  confidence: 0.0-1.0,
  detected_by: "manual|static_analysis|llm"
}]->(:Pattern)

// Function documented by
(:Function)-[:DOCUMENTED_BY {
  relevance: 0.0-1.0
}]->(:Documentation)

// Code pattern is instance of semantic pattern
(:CodePattern)-[:IS_INSTANCE_OF {
  similarity: 0.0-1.0
}]->(:Pattern)

// Function about concept
(:Function)-[:ABOUT {
  relevance: 0.0-1.0
}]->(:Concept)
```

### 4.3 Example Queries Spanning All Three

**Query 1: "Find all successful uses of Factory pattern in my codebase"**

```cypher
MATCH (pattern:Pattern {name: "Factory Pattern"})

// Semantic: What is it?
OPTIONAL MATCH (pattern)-[:DOCUMENTED_BY]->(doc:Documentation)

// Code: Where is it implemented?
OPTIONAL MATCH (f:Function)-[:IMPLEMENTS]->(pattern)
OPTIONAL MATCH (f)<-[:CONTAINS]-(cf:CodeFile)

// Episodic: How have we used it?
OPTIONAL MATCH (e:Episode)-[:DEMONSTRATES]->(pattern)
WHERE e.outcome = "success"

RETURN {
  pattern_info: {
    name: pattern.name,
    description: pattern.description,
    documentation: collect(DISTINCT doc.url)
  },
  implementations: collect(DISTINCT {
    function: f.name,
    file: cf.path,
    complexity: f.complexity
  }),
  successful_uses: collect(DISTINCT {
    when: e.timestamp,
    what: e.description,
    approach: e.approach,
    agent: e.agent_id
  })
}
ORDER BY e.timestamp DESC
```

**Query 2: "Context for debugging JWT authentication failure"**

```cypher
// Start with the error episode
MATCH (error_episode:Episode)
WHERE error_episode.description CONTAINS "JWT"
  AND error_episode.error IS NOT NULL
  AND error_episode.timestamp > datetime() - duration({days: 7})

// Code: What functions were involved?
MATCH (error_episode)-[:WORKED_ON]->(f:Function)
MATCH (jwt:Concept {name: "JWT"})
MATCH (f)-[:ABOUT]->(jwt)

// Semantic: What do we know about JWT errors?
OPTIONAL MATCH (jwt)-[:DOCUMENTED_BY]->(doc:Documentation)
WHERE doc.content CONTAINS "troubleshooting" OR doc.content CONTAINS "error"

// Semantic: What patterns apply?
OPTIONAL MATCH (jwt)<-[:APPLIES_TO]-(pattern:Pattern)

// Episodic: How did we fix similar errors before?
OPTIONAL MATCH (past_episode:Episode)
WHERE past_episode.description CONTAINS "JWT"
  AND past_episode.error IS NOT NULL
  AND past_episode.resolution IS NOT NULL
  AND past_episode.id <> error_episode.id

// Code: What patterns do working functions use?
OPTIONAL MATCH (working_f:Function)-[:ABOUT]->(jwt)
OPTIONAL MATCH (working_f)-[:IMPLEMENTS]->(pattern)
WHERE NOT exists((error_episode)-[:WORKED_ON]->(working_f))

RETURN {
  current_error: {
    description: error_episode.description,
    error: error_episode.error,
    when: error_episode.timestamp
  },
  involved_functions: collect(DISTINCT {
    name: f.name,
    file: f.file_path,
    calls: [(f)-[:CALLS]->(called) | called.name]
  }),
  troubleshooting_docs: collect(DISTINCT doc.url),
  applicable_patterns: collect(DISTINCT pattern.name),
  past_resolutions: collect(DISTINCT {
    when: past_episode.timestamp,
    error: past_episode.error,
    resolution: past_episode.resolution
  }),
  working_examples: collect(DISTINCT {
    function: working_f.name,
    pattern: pattern.name,
    file: working_f.file_path
  })
}
```

**Query 3: "Learn from all OAuth implementations across projects"**

```cypher
// Cross-project pattern learning
MATCH (oauth:Concept {name: "OAuth"})

// Code: Find all OAuth functions across ALL projects
MATCH (f:Function)-[:ABOUT]->(oauth)
MATCH (f)<-[:CONTAINS]-(cf:CodeFile)
OPTIONAL MATCH (cf)<-[:CONTAINS]-(p:Project)

// Episodic: Find all OAuth episodes across ALL projects
MATCH (e:Episode)-[:INVOLVED_CONCEPT]->(oauth)

// Semantic: Find patterns used
MATCH (pattern:Pattern)-[:APPLIES_TO]->(oauth)
OPTIONAL MATCH (f)-[:IMPLEMENTS]->(pattern)
OPTIONAL MATCH (e)-[:DEMONSTRATES]->(pattern)

// Aggregate learnings
WITH oauth, pattern,
     count(DISTINCT f) as function_count,
     count(DISTINCT CASE WHEN e.outcome = "success" THEN e END) as success_count,
     count(DISTINCT CASE WHEN e.outcome = "failure" THEN e END) as failure_count,
     collect(DISTINCT p.name) as projects_used

RETURN {
  concept: oauth.name,
  pattern: pattern.name,
  pattern_effectiveness: {
    implementations: function_count,
    successes: success_count,
    failures: failure_count,
    success_rate: success_count * 1.0 / (success_count + failure_count)
  },
  cross_project_adoption: projects_used,
  recommendation: CASE
    WHEN success_count * 1.0 / (success_count + failure_count) > 0.8 THEN "Highly Recommended"
    WHEN success_count * 1.0 / (success_count + failure_count) > 0.6 THEN "Recommended"
    ELSE "Use with Caution"
  END
}
ORDER BY success_count DESC
```

---

## 5. Knowledge Builder Agent Role

### 5.1 Current vs Proposed

**Current Implementation** (src/amplihack/knowledge_builder/):

```python
class KnowledgeBuilder:
    """Socratic Q&A + Web Search â†’ Markdown files"""

    def build(self) -> Path:
        # 1. Generate questions via Socratic method
        questions = self.question_gen.generate_all_questions(topic)

        # 2. Answer via web search
        questions = self.knowledge_acq.answer_all_questions(questions)

        # 3. Generate markdown artifacts
        artifacts = self.artifact_gen.generate_all(knowledge_graph)

        return output_dir  # Returns markdown files
```

**Proposed Enhancement** (Neo4j Integration):

```python
class KnowledgeBuilderNeo4j(KnowledgeBuilder):
    """Socratic Q&A + Web Search â†’ Neo4j + Markdown"""

    def __init__(self, topic: str, neo4j_connector):
        super().__init__(topic)
        self.connector = neo4j_connector
        self.extractor = KnowledgeExtractor()  # NEW

    def build(self) -> dict:
        # 1-2. Questions & Answers (unchanged from parent)
        questions = self.question_gen.generate_all_questions(self.topic)
        questions = self.knowledge_acq.answer_all_questions(questions, self.topic)

        # 3. Extract knowledge triplets (NEW)
        triplets = []
        for q in questions:
            extracted = self.extractor.extract_triplets(
                question=q.text,
                answer=q.answer
            )
            triplets.extend(extracted)

        # 4. Store in Neo4j semantic subgraph (NEW)
        kg_id = self._store_knowledge_graph(triplets)

        # 5. Generate markdown for human review (optional)
        markdown_dir = self.artifact_gen.generate_all(knowledge_graph)

        return {
            "knowledge_graph_id": kg_id,
            "markdown_dir": str(markdown_dir),
            "triplet_count": len(triplets),
            "question_count": len(questions)
        }

    def _store_knowledge_graph(self, triplets):
        """Store in semantic subgraph with source tracking."""
        kg_id = str(uuid.uuid4())

        # Create KnowledgeGraph container node
        self.connector.execute_query("""
            CREATE (kg:KnowledgeGraph {
                id: $id,
                topic: $topic,
                created_at: datetime(),
                question_count: $count,
                created_by: 'knowledge_builder'
            })
        """, {"id": kg_id, "topic": self.topic, "count": len(self.questions)})

        # Store each triplet
        for triplet in triplets:
            self.connector.execute_query("""
                // Merge concepts (avoid duplicates)
                MERGE (s:Concept {name: $subject})
                ON CREATE SET s.first_seen = datetime()

                MERGE (o:Concept {name: $object})
                ON CREATE SET o.first_seen = datetime()

                // Create knowledge fact relationship
                CREATE (s)-[r:KNOWLEDGE_FACT {
                    predicate: $predicate,
                    confidence: $confidence,
                    source_question: $question,
                    source_answer: $answer,
                    extracted_at: datetime()
                }]->(o)

                // Link to knowledge graph container
                WITH r
                MATCH (kg:KnowledgeGraph {id: $kg_id})
                CREATE (kg)-[:CONTAINS_FACT]->(r)
            """, {
                "subject": triplet.subject,
                "object": triplet.object,
                "predicate": triplet.predicate,
                "confidence": triplet.confidence,
                "question": triplet.source_question,
                "answer": triplet.source_answer,
                "kg_id": kg_id
            })

        return kg_id
```

### 5.2 Integration with Existing Agents

**How Other Agents Use Knowledge Builder**:

```python
class ArchitectAgentWithKnowledge:
    """Architect agent that queries unified graph."""

    def design_system(self, requirements: str):
        # Extract key concepts from requirements
        concepts = self._extract_concepts(requirements)  # e.g., ["OAuth", "REST API", "JWT"]

        # Query unified graph for context
        context = self.memory.get_context_for_task(
            agent_id="architect",
            task_description=requirements,
            concepts=concepts
        )

        # Context includes:
        # - Episodic: Past successful designs
        # - Semantic: OAuth documentation, patterns, best practices
        # - Code: Existing OAuth implementations

        # Design with full context
        design = self._create_design(requirements, context)

        # Record episode for future learning
        self.memory.record_episode(
            agent_id="architect",
            description=f"Designed system for {requirements}",
            approach=design.approach,
            outcome="pending",
            concepts=concepts
        )

        return design
```

**Knowledge Builder Triggers**:

1. **Manual**: User runs `/amplihack:knowledge-builder <topic>`
2. **Automatic**: When agent encounters unknown concept
   ```python
   if concept_not_in_graph(concept):
       kb = KnowledgeBuilderNeo4j(topic=concept, neo4j=connector)
       kb.build()  # Populates semantic subgraph
   ```
3. **Scheduled**: Nightly updates for documentation freshness
4. **Event-Driven**: When new documentation source added

### 5.3 Semantic Subgraph Population

**Knowledge Builder Workflow**:

```
Input: Topic (e.g., "Python asyncio")
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Socratic Question Generation     â”‚
â”‚    - What is asyncio?               â”‚
â”‚    - How do you create async tasks? â”‚
â”‚    - What are common pitfalls?      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Web Search & Answer Acquisition  â”‚
â”‚    - Search Python docs             â”‚
â”‚    - Search Real Python guides      â”‚
â”‚    - Search StackOverflow           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Knowledge Extraction (NEW)       â”‚
â”‚    Input: Q&A pairs                 â”‚
â”‚    Output: Triplets                 â”‚
â”‚    - (asyncio, IS_A, Python library)â”‚
â”‚    - (asyncio, ENABLES, concurrency)â”‚
â”‚    - (async, REQUIRES, event loop)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Neo4j Storage (NEW)              â”‚
â”‚    - Create/Merge Concept nodes     â”‚
â”‚    - Create KNOWLEDGE_FACT rels     â”‚
â”‚    - Link to KnowledgeGraph node    â”‚
â”‚    - Store source tracking metadata â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Markdown Generation (Optional)   â”‚
â”‚    - Human-readable summary         â”‚
â”‚    - For review and validation      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Output:
  - knowledge_graph_id: "uuid"
  - triplet_count: 47
  - markdown_dir: "path/to/markdown"
```

**Quality Control in Knowledge Builder**:

```python
class KnowledgeExtractor:
    """Extract triplets with quality control."""

    def extract_triplets(self, question: str, answer: str) -> List[Triplet]:
        # 1. LLM extraction
        raw_triplets = self._llm_extract(question, answer)

        # 2. Validation
        validated = []
        for triplet in raw_triplets:
            # Check confidence
            if triplet.confidence < 0.5:
                continue  # Skip low-confidence facts

            # Check for existing knowledge
            if self._conflicts_with_existing(triplet):
                # Trigger conflict resolution
                resolved = self._resolve_conflict(triplet)
                if resolved:
                    validated.append(resolved)
            else:
                validated.append(triplet)

        return validated

    def _resolve_conflict(self, new_triplet):
        """Multi-agent debate for conflicting knowledge."""
        # Get existing conflicting facts
        existing = self._get_conflicting_facts(new_triplet)

        # Use multi-agent debate (from /amplihack:debate pattern)
        resolution = self.debate_coordinator.resolve(
            new_fact=new_triplet,
            existing_facts=existing,
            perspectives=["accuracy", "recency", "source_credibility"]
        )

        if resolution.action == "replace":
            # Invalidate old fact (preserve history)
            self._invalidate_fact(existing, valid_until=datetime.now())
            return new_triplet
        elif resolution.action == "coexist":
            # Both can be true (e.g., multiple versions)
            return new_triplet
        else:  # "reject"
            return None
```

---

## 6. Revised Implementation Roadmap

### 6.1 Phase 1: Neo4j Memory System (27-35 hours)

**Status**: READY - Fully specified in Specs/Memory/

**Duration**: 3-4 weeks with 1 FTE
**Prerequisites**: None (foundation phase)

**Deliverables**:
- âœ… Neo4j Docker environment
- âœ… Episodic subgraph schema
- âœ… Agent type memory sharing
- âœ… Three-level hierarchy (global/project/instance)
- âœ… Multi-dimensional quality scoring
- âœ… Hybrid conflict resolution (70% auto, 25% debate, 5% human)
- âœ… CRUD operations for memory
- âœ… Agent integration hooks

**Tasks Breakdown**:

```
Week 1 (7-9 hours): Infrastructure + Schema
â”œâ”€ Day 1-2 (3-4h): Docker setup, Neo4j configuration
â”œâ”€ Day 3-4 (2-3h): Schema design (constraints, indexes)
â””â”€ Day 5 (2h): Connection management layer

Week 2 (8-10 hours): Core Operations
â”œâ”€ Day 1-2 (4-5h): CRUD operations (create, read, update, delete)
â”œâ”€ Day 3-4 (3-4h): Quality scoring implementation
â””â”€ Day 5 (1h): Conflict detection

Week 3 (8-11 hours): Agent Integration
â”œâ”€ Day 1-2 (4-5h): Agent type memory sharing
â”œâ”€ Day 3-4 (3-5h): Memory level isolation (global/project/instance)
â””â”€ Day 5 (1h): Context injection hooks

Week 4 (4-5 hours): Testing & Documentation
â”œâ”€ Day 1-2 (2-3h): Unit tests, integration tests
â””â”€ Day 3-5 (2h): Documentation, examples
```

**Success Criteria**:
- Memory operations complete in <50ms
- Agent type isolation verified
- Multi-level retrieval working
- Quality scoring accurate
- Zero memory leaks between projects

### 6.2 Phase 2: Knowledge Builder Neo4j Integration (58-78 hours)

**Status**: NEW - Designed in this synthesis
**Duration**: 1.5-2 months with 1 FTE
**Prerequisites**: Phase 1 complete

**Deliverables**:
- âœ… Semantic subgraph schema extension
- âœ… Knowledge extraction (triplets from Q&A)
- âœ… Neo4j storage for knowledge
- âœ… Unified query interface
- âœ… Bridge relationships (episodic â†” semantic)
- âœ… Quality control (confidence, validation, conflicts)

**Tasks Breakdown**:

```
Weeks 1-2 (12-18 hours): Schema + Extraction
â”œâ”€ Days 1-3 (4-6h): Extend Neo4j schema for semantic nodes
â”œâ”€ Days 4-7 (4-6h): Implement KnowledgeExtractor class
â””â”€ Days 8-10 (4-6h): Source tracking and metadata

Weeks 3-4 (12-16 hours): Knowledge Builder Refactor
â”œâ”€ Days 1-4 (6-8h): Refactor KnowledgeBuilder for Neo4j
â”œâ”€ Days 5-7 (4-6h): Storage operations (triplets â†’ Neo4j)
â””â”€ Day 8 (2h): Backward compatibility testing

Weeks 5-6 (12-16 hours): Unified Query Interface
â”œâ”€ Days 1-4 (6-8h): Create UnifiedQueryInterface class
â”œâ”€ Days 5-7 (4-6h): Implement cross-layer queries
â””â”€ Day 8 (2h): Query optimization

Weeks 7-8 (6-8 hours): Bridge Relationships
â”œâ”€ Days 1-3 (3-4h): Implement bridge creation logic
â”œâ”€ Days 4-5 (2-3h): Test bridge queries
â””â”€ Day 6 (1h): Documentation

Weeks 9-12 (16-20 hours): Testing & Documentation
â”œâ”€ Days 1-5 (8-10h): Comprehensive testing
â”œâ”€ Days 6-8 (4-6h): Performance benchmarking
â””â”€ Days 9-12 (4h): Documentation and examples
```

**Success Criteria**:
- Knowledge extraction >80% accuracy
- Triplet storage <100ms per triplet
- Cross-layer queries <200ms
- Unified query interface functional
- Bridge relationships working correctly

### 6.3 Phase 3: blarify Code Graph Integration (4-5 hours)

**Status**: SPECIFIED - Already designed
**Duration**: 1 week (can parallel with Phase 2 after Phase 1 done)
**Prerequisites**: Phase 1 complete

**Deliverables**:
- âœ… SCIP code graph import
- âœ… Code subgraph schema
- âœ… Bridge relationships (code â†” memory, code â†” knowledge)
- âœ… Incremental updates on code changes

**Tasks Breakdown**:

```
Day 1 (2-3 hours): SCIP Import
â”œâ”€ Setup blarify + SCIP integration
â”œâ”€ Import code graph to Neo4j
â””â”€ Verify node creation

Day 2 (2 hours): Bridge Relationships
â”œâ”€ Link Episode â†’ CodeFile (MODIFIED)
â”œâ”€ Link Function â†’ Pattern (IMPLEMENTS)
â””â”€ Link Function â†’ Concept (ABOUT)
```

**Success Criteria**:
- Code graph imports successfully
- Incremental updates work
- Bridge queries span code + memory
- 330x performance improvement vs LSP

### 6.4 Phase 4: Unified Querying and Advanced Features (40-60 hours)

**Status**: FUTURE - After all three subgraphs operational
**Duration**: 1-2 months
**Prerequisites**: Phases 1, 2, 3 complete

**Features**:

**4A. Graphiti Temporal Architecture (16-24 hours)**:
- Bi-temporal validity tracking (event time vs ingestion time)
- Historical preservation without recomputation
- LLM-based conflict resolution
- Temporal query support

**4B. Learning from Experience (12-16 hours)**:
- Auto-extract patterns from successful episodes
- Promote episodic â†’ semantic after repetition
- Confidence scoring based on evidence count
- Pattern effectiveness tracking

**4C. External Knowledge Integration (8-12 hours)**:
- Diffbot API for base knowledge layer (optional)
- MS Learn API integration
- StackOverflow knowledge extraction
- Version tracking and deprecation

**4D. Advanced Graph Analytics (4-8 hours)**:
- Community detection for concept clustering
- Pattern hierarchy identification
- Cross-domain connection discovery
- Graph visualization

**Success Criteria**:
- Temporal queries work correctly
- Learning loop promotes knowledge automatically
- External knowledge integrated seamlessly
- Advanced analytics provide insights

### 6.5 Timeline Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Month 1: Phase 1 (Neo4j Memory System)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Week 1: Infrastructure + Schema (7-9h)                        â”‚
â”‚ Week 2: Core Operations (8-10h)                               â”‚
â”‚ Week 3: Agent Integration (8-11h)                             â”‚
â”‚ Week 4: Testing + Documentation (4-5h)                        â”‚
â”‚                                                               â”‚
â”‚ DELIVERABLE: Episodic subgraph operational                    â”‚
â”‚ DECISION GATE: Continue to Phase 2? (metrics review)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Months 2-3: Phase 2 (Knowledge Builder Neo4j)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Weeks 5-6: Schema Extension + Knowledge Extraction (12-18h)   â”‚
â”‚ Weeks 7-8: Refactor Knowledge Builder (12-16h)                â”‚
â”‚ Weeks 9-10: Unified Query Interface (12-16h)                  â”‚
â”‚ Weeks 11-12: Bridge Relationships + Testing (22-28h)          â”‚
â”‚                                                               â”‚
â”‚ DELIVERABLE: Semantic subgraph operational                    â”‚
â”‚ DECISION GATE: Continue to Phase 3? (quality review)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Month 3 (parallel): Phase 3 (blarify Code Graph)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Week 1: SCIP Import + Bridge Relationships (4-5h)             â”‚
â”‚                                                               â”‚
â”‚ NOTE: Can run alongside Phase 2 (minimal dependencies)        â”‚
â”‚                                                               â”‚
â”‚ DELIVERABLE: Code subgraph operational, all bridges working   â”‚
â”‚ MILESTONE: Complete unified three-subgraph architecture       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Months 4-5: Phase 4 (Advanced Features)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Weeks 13-14: Graphiti Temporal Architecture (16-24h)          â”‚
â”‚ Weeks 15-16: Learning from Experience (12-16h)                â”‚
â”‚ Weeks 17-18: External Knowledge Integration (8-12h)           â”‚
â”‚ Week 19: Advanced Graph Analytics (4-8h)                      â”‚
â”‚                                                               â”‚
â”‚ DELIVERABLE: Production-ready unified knowledge graph system  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TOTAL TIMELINE: 4-5 months with 1 FTE
TOTAL EFFORT: 129-178 hours
```

### 6.6 Resource Requirements

**Phase 1 (Month 1)**:
- 1 Backend Developer (Python + Neo4j experience)
- Part-time DevOps support (Docker setup)
- Total: ~30 hours

**Phase 2 (Months 2-3)**:
- 1 Backend Developer (Python + Neo4j)
- Part-time AI Engineer (LLM integration)
- Total: ~60-70 hours

**Phase 3 (Week parallel to Phase 2)**:
- Same Backend Developer
- Total: ~5 hours

**Phase 4 (Months 4-5)**:
- 1 Backend Developer
- Part-time Data Scientist (graph analytics)
- Total: ~40-60 hours

**Grand Total**: 135-165 hours over 4-5 months

---

## 7. Amplifier Compatibility

### 7.1 JSON Export for Compatibility

**Support Amplifier's JSON Format**:

```python
class MemoryExporter:
    """Export Neo4j memory to Amplifier-compatible JSON."""

    def export_to_amplifier_format(self, project_id: str) -> dict:
        """Export project memories in Microsoft Amplifier JSON format."""

        memories = self.connector.execute_query("""
            MATCH (p:Project {id: $project_id})
            MATCH (p)-[:CONTAINS_MEMORY]->(m:Memory)
            OPTIONAL MATCH (m)-[:CREATED_BY]->(at:AgentType)

            RETURN {
                id: m.id,
                type: m.memory_type,
                content: m.content,
                metadata: {
                    source: at.name,
                    confidence: m.importance,
                    timestamp: toString(m.created_at),
                    tags: labels(m)
                },
                dedupKey: m.content  // For Amplifier's content hashing
            } as memory
            ORDER BY m.created_at DESC
        """, {"project_id": project_id})

        return {
            "format": "microsoft-amplifier-v1",
            "project": project_id,
            "memory_count": len(memories),
            "memories": [r["memory"] for r in memories],
            "exported_at": datetime.now().isoformat()
        }
```

### 7.2 Migration Path from Amplifier

**Import Amplifier JSON to Neo4j**:

```python
class AmplifierImporter:
    """Migrate from Microsoft Amplifier JSON to Neo4j."""

    def import_amplifier_memories(self, json_file: Path):
        """Import Amplifier JSON memories into Neo4j episodic subgraph."""

        data = json.loads(json_file.read_text())

        for memory in data["memories"]:
            # Extract metadata
            source = memory["metadata"].get("source", "unknown")
            confidence = memory["metadata"].get("confidence", 0.5)
            timestamp = memory["metadata"].get("timestamp")
            tags = memory["metadata"].get("tags", [])

            # Create Memory node
            self.connector.execute_query("""
                // Create or get AgentType
                MERGE (at:AgentType {id: $source})
                ON CREATE SET at.name = $source

                // Create Memory node
                CREATE (m:Memory {
                    id: $id,
                    memory_type: $type,
                    content: $content,
                    importance: $confidence,
                    created_at: datetime($timestamp),
                    imported_from: 'amplifier'
                })

                // Link to AgentType
                CREATE (at)-[:HAS_MEMORY]->(m)

                // Add tags as labels
                WITH m
                UNWIND $tags as tag
                CALL apoc.create.addLabels(m, [tag]) YIELD node
                RETURN m
            """, {
                "id": memory["id"],
                "type": memory["type"],
                "content": memory["content"],
                "confidence": confidence,
                "timestamp": timestamp,
                "source": source,
                "tags": tags
            })

        return {
            "imported_count": len(data["memories"]),
            "source": "microsoft-amplifier",
            "project": data.get("project", "unknown")
        }
```

### 7.3 Preserving Amplifier's Simplicity

**Keep What Works**:

1. **Hook-Based Extraction**: Use same lifecycle hooks as Amplifier
   ```python
   # Before agent execution
   @before_agent_execution
   def inject_memory_context(agent_id, task):
       context = memory.get_relevant(agent_id, task)
       agent.context = context

   # After agent execution
   @after_agent_execution
   def capture_memory(agent_id, task, result):
       memory.store(agent_id, task, result)
   ```

2. **Advisory Only**: Memory is always suggestive, never prescriptive
   ```python
   # Agent decision flow
   context_from_memory = memory.get_context(agent_id, task)
   # Agent considers but can override
   decision = agent.decide(task, context_from_memory)
   ```

3. **Graceful Degradation**: Works without memory
   ```python
   try:
       context = memory.get_context(agent_id, task)
   except MemoryUnavailable:
       context = {}  # Agent continues without memory
   ```

4. **Tag-Based Organization**: Use Neo4j labels like Amplifier's tags
   ```cypher
   // Tag-based retrieval
   MATCH (m:Memory:ImportantDecision)  // Multiple labels like tags
   WHERE m.content CONTAINS $keyword
   ```

5. **Metadata-Rich**: Every memory tracks source, confidence, timestamp
   ```cypher
   CREATE (m:Memory {
       content: $content,
       importance: $confidence,  // Like Amplifier's confidence
       created_at: datetime(),
       source: $agent_id,
       source_type: "agent_execution"
   })
   ```

**Where We Improve**:

- âœ… **Native Graph**: Real relationships vs JSON key-value
- âœ… **Scalability**: Millions of nodes vs ~10k limit
- âœ… **Cross-Layer Queries**: Traverse subgraphs vs isolated lookups
- âœ… **Deduplication**: Graph-native MERGE vs content hashing
- âœ… **Agent Type Sharing**: First-class concept vs manual routing

---

## 8. Decision Updates

### 8.1 Key Architectural Decisions

**Decision 1: Neo4j from Day 1 (Not SQLite-First)**

**Rationale**:
- User requirement: Graph database MANDATORY for code graph
- Technical superiority: 20% faster implementation, 67% simpler queries
- Economics: Break-even Month 1, 47% savings at 12 months
- Alternatives considered: SQLite-first (rejected due to migration cost)

**Impact**: CRITICAL - Foundation decision affecting all phases

---

**Decision 2: Unified Graph (Not Separate Systems)**

**Rationale**:
- Cross-layer queries essential for agent learning
- Simpler maintenance: One system vs dual APIs
- Knowledge grounding: Facts backed by experience
- Alternatives considered: Separate memory + knowledge systems (rejected)

**Impact**: HIGH - Enables key use cases, reduces complexity

---

**Decision 3: Three Subgraphs (Episodic, Semantic, Code)**

**Rationale**:
- Clear separation of concerns (what happened, what's known, what exists)
- Natural data models for each domain
- Bridge relationships connect without mixing
- Alternatives considered: Flat single-subgraph (rejected: unclear boundaries)

**Impact**: HIGH - Clean architecture, maintainable

---

**Decision 4: Agent Type Memory Sharing**

**Rationale**:
- User requirement: Agents of same type share memory
- Natural graph modeling: AgentType singleton nodes
- Efficient queries: "What do other architects know?"
- Alternatives considered: Per-agent isolation (rejected: violates requirement)

**Impact**: CRITICAL - Core user requirement

---

**Decision 5: Graphiti Pattern for Temporal Architecture**

**Rationale**:
- Proven performance: 94.8% accuracy, <300ms latency
- Bi-temporal model: Event time + ingestion time
- Conflict resolution without data loss
- Alternatives considered: Custom temporal logic (rejected: reinventing wheel)

**Impact**: MEDIUM-HIGH - Quality and correctness

---

**Decision 6: Knowledge Builder Populates Semantic Subgraph**

**Rationale**:
- Leverages existing Socratic Q&A system
- Extends with triplet extraction and Neo4j storage
- Backward compatible: Still generates markdown
- Alternatives considered: New separate knowledge system (rejected: duplication)

**Impact**: MEDIUM - Extends existing capability

---

**Decision 7: blarify for Code Graph (Not Custom AST Parser)**

**Rationale**:
- 330x faster than LSP
- SCIP protocol: Multi-language, incremental updates
- Existing tool, battle-tested
- Alternatives considered: Custom AST parser (rejected: complexity)

**Impact**: HIGH - Performance and reliability

---

**Decision 8: No ORM (Direct Cypher)**

**Rationale**:
- Aligns with zero-BS philosophy
- Cypher is readable: 3x less code than SQL JOINs
- No abstraction layer hiding graph nature
- Alternatives considered: Neo4j OGM (rejected: unnecessary abstraction)

**Impact**: MEDIUM - Code simplicity and clarity

---

### 8.2 Revisions from Initial Research

**Original Recommendation**: SQLite-first, migrate to Neo4j if needed

**Revised Recommendation**: Neo4j from Day 1

**Why the Change**:
- User provided EXPLICIT REQUIREMENT: Graph database mandatory
- Economics analysis showed Month 1 break-even (not Month 3-4)
- Technical superiority more compelling than initially assessed
- Migration cost (15-25 hours) avoided entirely

---

**Original Plan**: Separate memory and knowledge systems

**Revised Plan**: Unified temporal knowledge graph

**Why the Change**:
- Research revealed unified > separate (cross-layer queries)
- Graphiti/Zep pattern demonstrates unified architecture success
- Simpler maintenance: One system vs two
- Enables learning loop (episodic â†’ semantic)

---

**Original Scope**: Memory system only

**Revised Scope**: Memory + knowledge + code graph unified

**Why the Change**:
- Knowledge builder agent exists and needs integration
- blarify code graph already planned (Specs/Memory/)
- Bridge relationships unlock powerful use cases
- Complete vision more compelling than incremental

---

## 9. Success Metrics

### 9.1 Memory System Metrics

**Performance Metrics**:
- Memory operations: <50ms (target), <100ms (acceptable)
- Query latency: P50 <20ms, P95 <100ms, P99 <200ms
- Cache hit rate: >80% after warm-up period
- Write throughput: >100 memories/second

**Quality Metrics**:
- Memory relevance: >85% (agent feedback)
- Deduplication effectiveness: >95% (no duplicate concepts)
- Conflict resolution accuracy: >90% (validated against ground truth)
- Memory pollution rate: <5% (low-quality memories)

**Scalability Metrics**:
- Nodes supported: 1M+ without degradation
- Projects supported: 100+ concurrent
- Agent types supported: 50+ defined types
- Memory retention: 6 months default, configurable

### 9.2 Knowledge Graph Metrics

**Extraction Metrics**:
- Triplet extraction accuracy: >80% (validated by human review)
- Entity recognition precision: >85%
- Relationship extraction recall: >75%
- Confidence calibration: Within 10% of ground truth

**Quality Metrics**:
- Knowledge fact accuracy: >90% (spot-checked)
- Source tracking completeness: 100% (every fact has source)
- Temporal validity accuracy: >95% (bi-temporal model correct)
- Cross-validation rate: >80% (facts supported by multiple sources)

**Integration Metrics**:
- Knowledge builder runtime: <5 minutes for 20-question graph
- Neo4j storage time: <100ms per triplet
- Markdown generation: <30 seconds (optional human review)
- Backward compatibility: 100% (existing markdown-only mode works)

### 9.3 Integration Quality Metrics

**Bridge Relationship Metrics**:
- Bridge creation success: >99%
- Cross-layer query accuracy: >95%
- Query performance: <200ms for cross-layer queries
- Data consistency: 100% (no orphaned nodes)

**Agent Performance Impact**:
- Decision quality improvement: +25-40% (measured by outcome tracking)
- Error resolution improvement: +50-70% (repeat errors reduced)
- Time saved per agent action: 2-4 minutes (context retrieval vs manual lookup)
- Agent learning rate: Measurable improvement over 4-6 weeks

**System Health Metrics**:
- Memory overhead: <100MB per project
- Database size growth: <1GB per 100k memories
- Backup time: <5 minutes for full backup
- Restore time: <10 minutes for full restore

### 9.4 Economic Metrics

**Development ROI**:
- Break-even time: Month 1 (Neo4j setup costs recovered)
- 6-month ROI: 25% savings (maintenance + query development)
- 12-month ROI: 47% savings (compounding benefits)
- 24-month ROI: 51% savings (long-term economic win)

**Operational Cost**:
- Neo4j infrastructure: ~$50/month (Docker hosting)
- Storage costs: ~$10/month per 1M nodes
- Maintenance effort: 3-4 hours/month (vs 8-10 hours SQLite)
- Backup storage: ~$5/month

**Value Delivery**:
- Time saved per developer: 2-4 hours/week
- Error reduction: 50-70% fewer repeat errors
- Knowledge reuse: 30-50% reduction in research time
- Onboarding acceleration: 40% faster for new developers

---

## 10. Next Steps

### 10.1 Immediate Actions (This Week)

**1. Review and Approve This Synthesis**
- [ ] Stakeholder review meeting
- [ ] Architecture decisions validation
- [ ] Timeline and resource allocation approval

**2. Phase 1 Preparation**
- [ ] Create project branch: `feat/unified-memory-knowledge-system`
- [ ] Assign development team (1 FTE, part-time DevOps)
- [ ] Set up project tracking (Jira/GitHub Projects)

**3. Technical Preparation**
- [ ] Provision Neo4j Docker environment (development)
- [ ] Set up CI/CD for Neo4j migrations
- [ ] Create test data sets for validation

**4. Documentation**
- [ ] Share this synthesis with team
- [ ] Schedule architecture walkthrough
- [ ] Create implementation checklist from roadmap

### 10.2 Phase 1 Kickoff (Week 1)

**Day 1-2: Infrastructure**
- [ ] Neo4j Docker setup complete
- [ ] Connection pooling configured
- [ ] Development database accessible

**Day 3-4: Schema Design**
- [ ] Episodic subgraph schema implemented
- [ ] Constraints and indexes created
- [ ] Schema documented

**Day 5: Validation**
- [ ] Manual testing of schema
- [ ] Performance baseline measurement
- [ ] Week 1 retrospective

### 10.3 Phase Completion Gates

**Phase 1 Gate (End of Month 1)**:
- [ ] All success criteria met (memory ops <50ms, isolation working, etc.)
- [ ] Performance measurements documented
- [ ] Team retrospective completed
- [ ] Decision: Proceed to Phase 2?

**Phase 2 Gate (End of Month 3)**:
- [ ] Semantic subgraph operational
- [ ] Knowledge extraction >80% accuracy
- [ ] Cross-layer queries working
- [ ] Decision: Proceed to Phase 3?

**Phase 3 Gate (End of Month 3, parallel)**:
- [ ] Code graph imported successfully
- [ ] Bridge relationships functional
- [ ] All three subgraphs connected
- [ ] MILESTONE: Complete unified architecture

**Phase 4 Gate (End of Month 5)**:
- [ ] Advanced features operational
- [ ] Learning loop working
- [ ] System production-ready
- [ ] Final decision: Deploy to production?

### 10.4 Risk Mitigation

**High-Risk Areas**:
1. Neo4j learning curve (Mitigation: Training, pair programming)
2. Query performance at scale (Mitigation: Early benchmarking, optimization sprints)
3. Knowledge extraction accuracy (Mitigation: Human-in-the-loop validation, confidence thresholds)
4. Integration complexity (Mitigation: Incremental approach, comprehensive testing)

**Monitoring Plan**:
- Weekly performance reviews
- Bi-weekly architecture check-ins
- Monthly stakeholder updates
- Continuous integration testing

---

## 11. References

### 11.1 Internal Documentation

**Memory System Research**:
- `/Specs/Memory/` - Neo4j architecture specification
- `/docs/research/neo4j_memory_system/` - Comprehensive research (16 docs, 460KB)
- `/.claude/runtime/logs/20251102_neo4j_memory_revision/DECISIONS.md` - Decision log

**Knowledge Graph Research**:
- `/docs/research/KNOWLEDGE_GRAPH_SYSTEMS_RESEARCH_2025.md` - Systems research (68KB)
- `/docs/research/KNOWLEDGE_GRAPH_INTEGRATION_SUMMARY.md` - Integration guide
- `/docs/research/KNOWLEDGE_GRAPH_RESEARCH_INDEX.md` - Research index

**Project Context**:
- `/.claude/context/PHILOSOPHY.md` - Ruthless simplicity principles
- `/.claude/context/PROJECT.md` - Project mission and objectives
- `/.claude/context/PATTERNS.md` - Proven solution patterns
- `/CLAUDE.md` - Project instructions and workflow

### 11.2 External Resources

**Neo4j**:
- Neo4j Documentation: https://neo4j.com/docs/
- Cypher Query Language: https://neo4j.com/docs/cypher-manual/current/
- Neo4j Python Driver: https://neo4j.com/docs/python-manual/current/

**Knowledge Graph Systems**:
- Graphiti/Zep: https://github.com/getzep/graphiti
- Neo4j LLM Graph Builder: https://github.com/neo4j-labs/llm-graph-builder
- LangChain Neo4j: https://python.langchain.com/docs/integrations/graphs/neo4j_cypher/

**Code Analysis**:
- blarify: https://github.com/blarApp/blarify
- SCIP Protocol: https://github.com/sourcegraph/scip

**Research Papers**:
- Zep: Temporal Knowledge Graph Architecture (arXiv:2501.13956v1, Jan 2025)
- Graph4Code: Toolkit for Code Knowledge Graphs (ACM K-CAP 2021)

### 11.3 Research Statistics

**Total Research**:
- Documents analyzed: 30+ (memory + knowledge + code graph)
- Total size: 843KB + 460KB + 113KB = 1.4MB
- Research duration: 3 days (multi-agent parallel execution)
- Agents involved: architect, database, patterns, knowledge-archaeologist, explore

**Deliverables**:
- Comprehensive reports: 3
- Technical specifications: 5
- Decision logs: 2
- Integration guides: 4
- Code examples: 10+

---

## Conclusion

This synthesis presents a complete, actionable architecture for amplihack's unified memory and knowledge graph system. The three-subgraph design (episodic, semantic, code) addresses user requirements while maintaining ruthless simplicity.

**Key Insights**:
1. **Neo4j from Day 1** is both technically superior and economically favorable
2. **Unified architecture** beats separate systems for cross-layer queries and agent learning
3. **Three subgraphs** provide clear separation while bridge relationships enable integration
4. **Knowledge builder** naturally extends to populate semantic subgraph
5. **Microsoft Amplifier** lessons inform simplicity while graph enables scale

**Ready for Implementation**: All phases specified with clear success criteria, timelines, and resource requirements. Phase 1 can begin immediately.

**Expected Impact**: 25-40% better decisions, 50-70% fewer errors, 2-4 hours saved per developer per week, positive ROI within 3-4 months.

---

**Document Status**: âœ… COMPLETE
**Date**: November 2, 2025
**Synthesized By**: Architect Agent (Claude Code)
**Approved For**: Implementation Planning
